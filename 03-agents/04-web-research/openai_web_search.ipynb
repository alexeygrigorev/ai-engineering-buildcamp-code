{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e98557-1ea7-4f7f-bed2-7fc0a7294c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b74772-cfdd-4753-8dd3-3e6311b36efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78060e9-3fab-41d9-bf1a-9f438b8ac0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool 5.7677531242370605 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "instructions = \"\"\"\n",
    "You're a research agent, your task is to find articles on the internet and \n",
    "answer the question from the user. Make sure you include references in the \n",
    "answer you generate\n",
    "\"\"\"\n",
    "user_prompt = \"How do I do RAG in 2026?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(f'took {end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdaad0a5-076a-41d1-92a4-7816f7ad8358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation (RAG) has become a cornerstone in the development of advanced AI systems, particularly in enterprise applications, as of 2026. RAG integrates large language models (LLMs) with external knowledge sources to enhance the accuracy and relevance of generated content. To implement RAG effectively in 2026, consider the following steps:\n",
      "\n",
      "1. **Understand the RAG Architecture**: RAG systems typically consist of two main components: a retriever and a generator. The retriever searches an external knowledge base to find relevant information, while the generator uses this information to produce contextually accurate responses.\n",
      "\n",
      "2. **Select Appropriate Tools and Frameworks**: In 2026, several tools and frameworks have been developed to facilitate the building of RAG systems. For instance, the \"Build RAG from Scratch\" session at NDC London 2026 provides insights into constructing RAG components, including vectorization, similarity search, embedding models, and vector databases. ([websites.internal.ndcconferences.com](https://websites.internal.ndcconferences.com/agenda/build-rag-from-scratch-0igd/0bzmnii2cji?utm_source=openai))\n",
      "\n",
      "3. **Implement Advanced Retrieval Mechanisms**: Modern RAG systems employ sophisticated retrieval strategies to improve performance. Techniques such as hierarchical retrieval interfaces, as seen in the A-RAG framework, allow models to adaptively search and retrieve information across multiple granularities, enhancing the system's ability to handle complex queries. ([arxiv.org](https://arxiv.org/abs/2602.03442?utm_source=openai))\n",
      "\n",
      "4. **Ensure Robustness and Adaptability**: To build resilient RAG systems, it's crucial to address challenges like retrieval noise and evidence selection. The BAR-RAG framework introduces boundary-aware evidence selection, training the system to identify and utilize evidence that is challenging yet sufficient for inference, thereby improving robustness under noisy retrieval conditions. ([arxiv.org](https://arxiv.org/abs/2602.03689?utm_source=openai))\n",
      "\n",
      "5. **Stay Informed on Industry Trends**: The field of RAG is rapidly evolving. Recent developments include the integration of graphs and hypergraphs to capture complex relationships within data, as explored in the IGMiRAG framework, which constructs hierarchical heterogeneous hypergraphs to align multi-granular knowledge. ([arxiv.org](https://arxiv.org/abs/2602.07525?utm_source=openai))\n",
      "\n",
      "By following these steps and leveraging current research and tools, you can effectively implement RAG systems in 2026, ensuring they are both efficient and adaptable to the dynamic needs of enterprise applications. \n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a78586-1590-49c9-93f8-3f7dfb9dae48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFunctionWebSearch(id='ws_04f6e9c30f7bb5e000698f9aeacc0481a29096e4a1639efa0d', action=ActionSearch(query='RAG 2026 methodology research articles', type='search', queries=['RAG 2026 methodology research articles'], sources=None), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseOutputMessage(id='msg_04f6e9c30f7bb5e000698f9aeb977c81a2aace22702b4d2810', content=[ResponseOutputText(annotations=[AnnotationURLCitation(end_index=1159, start_index=1008, title='Build RAG from Scratch | NDC London 2026', type='url_citation', url='https://websites.internal.ndcconferences.com/agenda/build-rag-from-scratch-0igd/0bzmnii2cji?utm_source=openai'), AnnotationURLCitation(end_index=1593, start_index=1528, title='A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces', type='url_citation', url='https://arxiv.org/abs/2602.03442?utm_source=openai'), AnnotationURLCitation(end_index=2049, start_index=1984, title='Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2602.03689?utm_source=openai'), AnnotationURLCitation(end_index=2440, start_index=2375, title='IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory', type='url_citation', url='https://arxiv.org/abs/2602.07525?utm_source=openai')], text='Retrieval-Augmented Generation (RAG) has become a cornerstone in the development of advanced AI systems, particularly in enterprise applications, as of 2026. RAG integrates large language models (LLMs) with external knowledge sources to enhance the accuracy and relevance of generated content. To implement RAG effectively in 2026, consider the following steps:\\n\\n1. **Understand the RAG Architecture**: RAG systems typically consist of two main components: a retriever and a generator. The retriever searches an external knowledge base to find relevant information, while the generator uses this information to produce contextually accurate responses.\\n\\n2. **Select Appropriate Tools and Frameworks**: In 2026, several tools and frameworks have been developed to facilitate the building of RAG systems. For instance, the \"Build RAG from Scratch\" session at NDC London 2026 provides insights into constructing RAG components, including vectorization, similarity search, embedding models, and vector databases. ([websites.internal.ndcconferences.com](https://websites.internal.ndcconferences.com/agenda/build-rag-from-scratch-0igd/0bzmnii2cji?utm_source=openai))\\n\\n3. **Implement Advanced Retrieval Mechanisms**: Modern RAG systems employ sophisticated retrieval strategies to improve performance. Techniques such as hierarchical retrieval interfaces, as seen in the A-RAG framework, allow models to adaptively search and retrieve information across multiple granularities, enhancing the system\\'s ability to handle complex queries. ([arxiv.org](https://arxiv.org/abs/2602.03442?utm_source=openai))\\n\\n4. **Ensure Robustness and Adaptability**: To build resilient RAG systems, it\\'s crucial to address challenges like retrieval noise and evidence selection. The BAR-RAG framework introduces boundary-aware evidence selection, training the system to identify and utilize evidence that is challenging yet sufficient for inference, thereby improving robustness under noisy retrieval conditions. ([arxiv.org](https://arxiv.org/abs/2602.03689?utm_source=openai))\\n\\n5. **Stay Informed on Industry Trends**: The field of RAG is rapidly evolving. Recent developments include the integration of graphs and hypergraphs to capture complex relationships within data, as explored in the IGMiRAG framework, which constructs hierarchical heterogeneous hypergraphs to align multi-granular knowledge. ([arxiv.org](https://arxiv.org/abs/2602.07525?utm_source=openai))\\n\\nBy following these steps and leveraging current research and tools, you can effectively implement RAG systems in 2026, ensuring they are both efficient and adaptable to the dynamic needs of enterprise applications. ', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in response.output:\n",
    "    print(m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b190eae-8a5a-4b3c-a0e7-34c30ebe2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc, o = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f836cd19-c5e5-4dc7-8c5a-6f556c11f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build RAG from Scratch | NDC London 2026\n",
      "https://websites.internal.ndcconferences.com/agenda/build-rag-from-scratch-0igd/0bzmnii2cji?utm_source=openai\n",
      "\n",
      "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces\n",
      "https://arxiv.org/abs/2602.03442?utm_source=openai\n",
      "\n",
      "Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation\n",
      "https://arxiv.org/abs/2602.03689?utm_source=openai\n",
      "\n",
      "IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory\n",
      "https://arxiv.org/abs/2602.07525?utm_source=openai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in o.content[0].annotations:\n",
    "    print(a.title)\n",
    "    print(a.url)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d443ce1-0c6c-4371-94ba-b978998dda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 45.541951417922974 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(f'took {end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93fd8059-bbb0-4e2c-b9f3-b4d306fda957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseReasoningItem(id='rs_03f6c8690264cc2700698f9becbe4c81919d4fc10e65b2530e', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_03f6c8690264cc2700698f9bf0f03c8191bf605fe8b2e3f1b1', action=ActionSearch(query='Retrieval augmented generation best practices 2024 2025 2026', type='search', queries=['Retrieval augmented generation best practices 2024 2025 2026', 'LangChain RAG 2026 guide', 'LlamaIndex RAG 2026 guide', 'OpenAI Retrieval API RAG 2024 2025 2026'], sources=None), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_03f6c8690264cc2700698f9bf243988191a5f4832a0733098e', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_03f6c8690264cc2700698f9bf3a1048191979b192bd172a251', action=ActionSearch(query='Pinecone 2026 features vector database', type='search', queries=['Pinecone 2026 features vector database', 'Weaviate 2026 vector search features', 'Chroma 2026 open source vector database', 'Qdrant 2026 features'], sources=None), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_03f6c8690264cc2700698f9bf4d844819186effb49a7a3685a', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_03f6c8690264cc2700698f9bf63edc81919f1843fe44210f92', action=ActionSearch(query='LlamaIndex RAG 2026 docs', type='search', queries=['LlamaIndex RAG 2026 docs', 'LlamaIndex retrieval-augmented generation 2025 2026'], sources=None), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_03f6c8690264cc2700698f9bf78abc819190bc48bc9907a525', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseOutputMessage(id='msg_03f6c8690264cc2700698f9c0550848191bafc33ac3b206e1d', content=[ResponseOutputText(annotations=[AnnotationURLCitation(end_index=907, start_index=810, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=1537, start_index=1468, title='LlamaIndex - LlamaIndex', type='url_citation', url='https://docs.llamaindex.ai/?utm_source=openai'), AnnotationURLCitation(end_index=2005, start_index=1908, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=2451, start_index=2388, title='Open Source Vector Database | Weaviate', type='url_citation', url='https://weaviate.io/platform?utm_source=openai'), AnnotationURLCitation(end_index=3013, start_index=2948, title='RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2501.13726?utm_source=openai'), AnnotationURLCitation(end_index=3491, start_index=3394, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=3924, start_index=3859, title='RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2501.13726?utm_source=openai'), AnnotationURLCitation(end_index=4357, start_index=4260, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=4942, start_index=4879, title='Open Source Vector Database | Weaviate', type='url_citation', url='https://weaviate.io/platform?utm_source=openai'), AnnotationURLCitation(end_index=5447, start_index=5382, title='A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces', type='url_citation', url='https://arxiv.org/abs/2602.03442?utm_source=openai'), AnnotationURLCitation(end_index=5712, start_index=5615, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=5919, start_index=5822, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=6165, start_index=6032, title=\"Pinecone's vector database gets a new serverless architecture | TechCrunch\", type='url_citation', url='https://techcrunch.com/2024/01/16/pinecones-vector-database-gets-a-new-serverless-architecture/?utm_source=openai'), AnnotationURLCitation(end_index=6406, start_index=6309, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=6963, start_index=6866, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=7202, start_index=7105, title='Build a RAG agent with LangChain - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai'), AnnotationURLCitation(end_index=7339, start_index=7270, title='LlamaIndex - LlamaIndex', type='url_citation', url='https://docs.llamaindex.ai/?utm_source=openai'), AnnotationURLCitation(end_index=7491, start_index=7428, title='Open Source Vector Database | Weaviate', type='url_citation', url='https://weaviate.io/platform?utm_source=openai'), AnnotationURLCitation(end_index=7695, start_index=7562, title=\"Pinecone's vector database gets a new serverless architecture | TechCrunch\", type='url_citation', url='https://techcrunch.com/2024/01/16/pinecones-vector-database-gets-a-new-serverless-architecture/?utm_source=openai'), AnnotationURLCitation(end_index=7886, start_index=7821, title='RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2501.13726?utm_source=openai')], text='Short answer: do RAG in 2026 by building the familiar pipeline (ingest → embed → index → retrieve → generate), but updated for today’s best tools and practices: pick a modern orchestration layer (LangChain or LlamaIndex), a production-grade vector store (Pinecone / Weaviate / Qdrant / Chroma), an appropriate embedding model (cloud or local), multi-stage retrieval + reranking, and instrumentation + trust layers (relevance graders, citation/attribution, monitoring). Below is a concise, practical how-to with concrete next steps and references.\\n\\nQuick overview (one line)\\n- RAG = keep your LLM honest by retrieving grounded context from an indexed corpus and feeding that context into the model at generation time. Use hybrid retrieval, reranking, and provenance to reduce hallucinations and scale reliably. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\nStep-by-step checklist (practical)\\n\\n1) Define the scope and SLA\\n- What data (docs, DBs, internal systems, email, PDFs)? Freshness requirements? Latency/cost targets? This determines embedding refresh cadence, vector DB choice, and caching.\\n\\n2) Ingest & preprocess\\n- Extract text (OCR for scanned PDFs), normalize, keep provenance metadata (doc id, page, timestamps, author, URL). Split into chunks sized for your LLM context window (typical 500–1,500 tokens with overlaps of 50–200 tokens; tune per model). Many failures trace back to bad chunking/ingestion. ([docs.llamaindex.ai](https://docs.llamaindex.ai/?utm_source=openai))\\n\\n3) Embeddings\\n- Choose embedding model by cost/quality/privacy: managed cloud embeddings (e.g., OpenAI text-embedding-* models) for convenience and quality, or local/embedding models if you need on‑prem/private inference. Generate embeddings in batches and store alongside metadata. (LangChain and other frameworks include integrations for common embedding providers.) ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\n4) Choose a vector store (index)\\n- Production options in 2026 include Weaviate (open-source with hybrid search, vectorizer integrations, multi-tenancy), Pinecone (serverless production vector DB), Qdrant, Chroma, Redis/Milvus, etc. Pick on features you need: managed vs self-host (privacy), hybrid BM25 + vector support, scaling/latency, multi-vector support, and access controls. ([weaviate.io](https://weaviate.io/platform?utm_source=openai))\\n\\n5) Retrieval strategy (multi-stage)\\n- Stage 1: fast ANN vector lookup (k large to maximize recall).\\n- Stage 2: optional sparse filter (BM25/keyword) or metadata filter to reduce candidates.\\n- Stage 3: neural reranker / cross-encoder or small “relevance grader” model to pick the final set to pass to the LLM (improves faithfulness). Research shows end‑to‑end and retrieval-aware retriever tuning improves final accuracy — consider training/tuning the retriever for the downstream RAG objective. ([arxiv.org](https://arxiv.org/abs/2501.13726?utm_source=openai))\\n\\n6) Formatting context for the LLM\\n- Concise prompt templates: include only the top N scored chunks (respect token budget), include provenance lines (doc/page/score) and an instruction to \"answer only using the provided sources; if not present say \\'I don\\'t know\\'.\" Use a condense/merge step (short generator) when you need to compress many retrieved chunks into a single context. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\n7) Reduce hallucinations and improve faithfulness\\n- Use multi-stage reranking, relevancy graders, truth‑checks, chain-of-evidence prompts, ask the model to cite source ids/quotes, and use small verification models to validate key facts. New papers (RPO / OpenRAG / relevance-grader work) show retriever-aware tuning and lightweight graders greatly help RAG quality. ([arxiv.org](https://arxiv.org/abs/2501.13726?utm_source=openai))\\n\\n8) Monitoring, evaluation and tooling\\n- Track retrieval metrics (recall@k, MRR), downstream answer quality (precision/ROUGE/F1 on eval set), and hallucination rate. Use tracing and logging tools (LangSmith or equivalent) to inspect chains and latencies. Add automated regression tests when you change ingestion or retriever settings. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\n9) Operational concerns\\n- Caching: cache embeddings and query results; precompute for heavy documents.\\n- Latency: async embedding/queries; tune vector store index and replication for QPS.\\n- Cost: balance embedding model cost vs frequency of re-embedding; compress or dedupe embeddings when possible.\\n- Security/privacy: if data is sensitive, host vector DB and models on-prem / in VPC, encrypt vectors, and implement strict access controls. Many vector DBs (Weaviate, Pinecone) support self-host or private deployments. ([weaviate.io](https://weaviate.io/platform?utm_source=openai))\\n\\n10) Advanced & future-proofing (2026 patterns)\\n- Agentic/interactive RAG: give the model retrieval tools so it can iteratively retrieve different granularities (keyword + semantic + chunk read) — this improves multi‑hop and complex tasks.\\n- Multi-modal RAG: index images/audio with multi-modal embeddings.\\n- End‑to‑end retriever tuning: tune retriever with the downstream objective (OpenRAG-style) for consistent relevance to generation. ([arxiv.org](https://arxiv.org/abs/2602.03442?utm_source=openai))\\n\\nMinimal starter architecture (recommended stack in 2026)\\n- Orchestration / developer API: LangChain or LlamaIndex (both have up-to-date RAG workflows and tutorials). ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n- Embeddings: OpenAI embeddings (or local sentence-transformers / Mistral/other embedder if privacy needed). ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n- Vector DB: Pinecone (serverless, managed) or Weaviate (open-source + hybrid search) depending on privacy/ops. ([techcrunch.com](https://techcrunch.com/2024/01/16/pinecones-vector-database-gets-a-new-serverless-architecture/?utm_source=openai))\\n- LLM: cloud LLM (OpenAI / Anthropic / Google / Mistral) or local LLM for on-device/offline cases.\\n- Monitoring: LangSmith / custom telemetry. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\nTiny example (pseudo-steps — use the library docs for exact code)\\n- Load documents → split into chunks with overlap → embed chunks → upsert vectors + metadata into vector DB → when query arrives: embed query → vector DB search (k=50) → rerank top candidates with a cross-encoder / small grader → pass top M chunks to LLM with a grounding prompt that requests citations → return answer + sources. For runnable samples, see LangChain and LlamaIndex tutorials. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n\\nReferences / reading (short list — start here)\\n- LangChain RAG docs & tutorial (practical pipeline, embeddings + vectorstore integrations). ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/rag?utm_source=openai))\\n- LlamaIndex docs (fast ingestion + starter examples for doc Q&A). ([docs.llamaindex.ai](https://docs.llamaindex.ai/?utm_source=openai))\\n- Weaviate docs / platform (hybrid search, self-host options, vectorizer integrations). ([weaviate.io](https://weaviate.io/platform?utm_source=openai))\\n- Pinecone serverless (production vector DB architecture discussion). ([techcrunch.com](https://techcrunch.com/2024/01/16/pinecones-vector-database-gets-a-new-serverless-architecture/?utm_source=openai))\\n- Recent RAG research (retriever-aware tuning / RPO and OpenRAG) for improving retrieval quality and end‑to‑end performance. ([arxiv.org](https://arxiv.org/abs/2501.13726?utm_source=openai))\\n\\nIf you want, I can:\\n- Scaffold a tiny end‑to‑end example (Python or Node) that uses LangChain or LlamaIndex + a free vector DB (Chroma/Qdrant) and an OpenAI trial key, OR\\n- Help choose a stack (managed vs self-host) given your constraints (data sensitivity, QPS, cost) — tell me about your data size, privacy needs, latency targets, and preferred programming language.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in response.output:\n",
    "    print(m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a31a52c9-84da-44ad-a1e7-0e0b324ef7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 41.921873569488525 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=messages,\n",
    "    include=[\"web_search_call.action.sources\"],\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(f'took {end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0fcb2cc-af82-4e11-bf26-904a07f96e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseReasoningItem(id='rs_07768c3bd244553600698f9cde8c6881928ce073fab4097359', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_07768c3bd244553600698f9ce0de508192bb05c8a7fb8d47f4', action=ActionSearch(query='Retrieval-augmented generation RAG 2026 best practices', type='search', queries=['Retrieval-augmented generation RAG 2026 best practices', 'RAG architecture 2024 2025 2026 LangChain LlamaIndex guide', 'How to implement RAG OpenAI retrieval-augmented generation docs 2024 2025', 'RAG evaluation metrics hallucination mitigation 2025 2026 research'], sources=[ActionSearchSource(type='url', url='https://arxiv.org/abs/2602.03689'), ActionSearchSource(type='url', url='https://arxiv.org/abs/2509.25669'), ActionSearchSource(type='url', url='https://arxiv.org/abs/2504.05324'), ActionSearchSource(type='url', url='https://arxiv.org/abs/2503.21157'), ActionSearchSource(type='url', url='https://www.dxtalks.com/blog/news-2/retrieval-augmented-generation-835'), ActionSearchSource(type='url', url='https://jishulabs.com/blog/rag-retrieval-augmented-generation-guide-2026'), ActionSearchSource(type='url', url='https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures'), ActionSearchSource(type='url', url='https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results'), ActionSearchSource(type='url', url='https://medium.com/%40globalbizoutlook/rag-models-complete-guide-to-retrieval-augmented-generation-for-enterprise-ai-in-2026-741e3b39a7ca'), ActionSearchSource(type='url', url='https://latestfromtechguy.com/article/rag-best-practices-2026'), ActionSearchSource(type='url', url='https://www.emergentmind.com/articles/2407.01219'), ActionSearchSource(type='url', url='https://www.morphik.ai/blog/retrieval-augmented-generation-strategies')]), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_07768c3bd244553600698f9ce228d881929ddbfb46f9996da0', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_07768c3bd244553600698f9ce3963c8192a7fce58bd23fe426', action=ActionSearch(query='OpenAI embeddings text-embedding-3-large documentation 2024 2025', type='search', queries=['OpenAI embeddings text-embedding-3-large documentation 2024 2025', \"OpenAI retrieval augmented generation guide 'retrieval' 'OpenAI' 2024 2025\"], sources=[ActionSearchSource(type='url', url='https://openai.com/index/new-embedding-models-and-api-updates/'), ActionSearchSource(type='url', url='https://platform.openai.com/docs/models/text-embedding-3-large'), ActionSearchSource(type='url', url='https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts%3F.iso'), ActionSearchSource(type='url', url='https://developers.openai.com/api/docs/models/text-embedding-3-large'), ActionSearchSource(type='url', url='https://platform.openai.com/docs/guides/retrieval'), ActionSearchSource(type='url', url='https://platform.openai.com/docs/guides/embeddings/embedding-models%20.class'), ActionSearchSource(type='url', url='https://help.openai.com/en/articles/6824809-embeddings-frequently-asked-questions%3F.iso')]), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_07768c3bd244553600698f9ce48e548192996107bacd346b73', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_07768c3bd244553600698f9ce505dc8192a93ab63fd4a1169c', action=ActionSearch(query=\"LangChain RAG guide 2025 2026 'retrieval augmented generation' LangChain docs\", type='search', queries=[\"LangChain RAG guide 2025 2026 'retrieval augmented generation' LangChain docs\", \"LlamaIndex RAG guide 2025 2026 'LlamaIndex retrieval augmented generation'\"], sources=[ActionSearchSource(type='url', url='https://docs.langchain.com/oss/javascript/langchain/retrieval'), ActionSearchSource(type='url', url='https://ts.llamaindex.ai/docs/llamaindex/tutorials/rag'), ActionSearchSource(type='url', url='https://docs.llamaindex.ai/en/stable/understanding/rag/'), ActionSearchSource(type='url', url='https://www.langchain.com/retrieval'), ActionSearchSource(type='url', url='https://docs.langchain.com/oss/python/langchain/retrieval'), ActionSearchSource(type='url', url='https://docs.llamaindex.ai/en/v0.10.34/getting_started/concepts/'), ActionSearchSource(type='url', url='https://docs.langchain.com/oss/python/langchain/rag'), ActionSearchSource(type='url', url='https://ts.llamaindex.ai/docs/llamaindex/tutorials/agents/4_agentic_rag')]), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_07768c3bd244553600698f9ce61618819285f98418d81648e1', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseFunctionWebSearch(id='ws_07768c3bd244553600698f9ce6c6ac8192b1e166e0240e87db', action=ActionSearch(query=\"Qdrant RAG best practices 2025 2026 vector database 'Qdrant' 'RAG'\", type='search', queries=[\"Qdrant RAG best practices 2025 2026 vector database 'Qdrant' 'RAG'\", \"Milvus RAG guide 2025 'Milvus' 'RAG'\"], sources=[ActionSearchSource(type='url', url='https://arxiv.org/abs/2511.16681'), ActionSearchSource(type='url', url='https://qdrant.tech/rag/'), ActionSearchSource(type='url', url='https://medium.com/%40Nomidl/building-a-powerful-rag-system-with-qdrant-advanced-techniques-for-smarter-retrieval-cd51dd5284a4'), ActionSearchSource(type='url', url='https://arxiv.org/abs/2601.05270'), ActionSearchSource(type='url', url='https://milvus.io/docs/build-rag-with-milvus.md'), ActionSearchSource(type='url', url='https://leaper.dev/blog/vector-databases-compared-2026'), ActionSearchSource(type='url', url='https://blog.milvus.io/docs/v2.4.x/integrate_with_llamaindex.md'), ActionSearchSource(type='url', url='https://blog.milvus.io/docs/milvus_rag_with_vllm.md'), ActionSearchSource(type='url', url='https://blog.milvus.io/docs/rag_with_langflow.md'), ActionSearchSource(type='url', url='https://milvus.io/docs/v2.5.x/rag_with_milvus_and_unstructured.md'), ActionSearchSource(type='url', url='https://blog.milvus.io/docs/v2.4.x/integrate_with_langchain.md')]), status='completed', type='web_search_call')\n",
      "\n",
      "ResponseReasoningItem(id='rs_07768c3bd244553600698f9ce9267c81929f89e8eeb41661e5', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)\n",
      "\n",
      "ResponseOutputMessage(id='msg_07768c3bd244553600698f9cee8de48192abb07a4722883cb5', content=[ResponseOutputText(annotations=[AnnotationURLCitation(end_index=761, start_index=622, title='\\u200b\\u200bRAG is dead: why enterprises are shifting to agent-based AI architectures', type='url_citation', url='https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures?utm_source=openai'), AnnotationURLCitation(end_index=1062, start_index=912, title='7 Best Practices for RAG Implementation That Actually Improve Your AI Results | ChatRAG Blog', type='url_citation', url='https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai'), AnnotationURLCitation(end_index=1325, start_index=1220, title='text-embedding-3-large Model | OpenAI API', type='url_citation', url='https://platform.openai.com/docs/models/text-embedding-3-large?utm_source=openai'), AnnotationURLCitation(end_index=1540, start_index=1437, title='RAG in 2025: 7 Proven Strategies to Deploy Retrieval-Augmented Generation at Scale | Morphik Blog', type='url_citation', url='https://www.morphik.ai/blog/retrieval-augmented-generation-strategies?utm_source=openai'), AnnotationURLCitation(end_index=1791, start_index=1726, title='Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2602.03689?utm_source=openai'), AnnotationURLCitation(end_index=2120, start_index=1967, title='Retrieval Augmented Generation (RAG) and Semantic Search for GPTs | OpenAI Help Center', type='url_citation', url='https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts%3F.iso?utm_source=openai'), AnnotationURLCitation(end_index=2342, start_index=2277, title='Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?', type='url_citation', url='https://arxiv.org/abs/2503.21157?utm_source=openai'), AnnotationURLCitation(end_index=2653, start_index=2503, title='7 Best Practices for RAG Implementation That Actually Improve Your AI Results | ChatRAG Blog', type='url_citation', url='https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai'), AnnotationURLCitation(end_index=2979, start_index=2883, title='New embedding models and API updates | OpenAI', type='url_citation', url='https://openai.com/index/new-embedding-models-and-api-updates/?utm_source=openai'), AnnotationURLCitation(end_index=3243, start_index=3184, title='RAG Use Case: Advanced Vector Search for AI Applications - Qdrant', type='url_citation', url='https://qdrant.tech/rag/?utm_source=openai'), AnnotationURLCitation(end_index=3505, start_index=3402, title='RAG in 2025: 7 Proven Strategies to Deploy Retrieval-Augmented Generation at Scale | Morphik Blog', type='url_citation', url='https://www.morphik.ai/blog/retrieval-augmented-generation-strategies?utm_source=openai'), AnnotationURLCitation(end_index=3822, start_index=3719, title='Retrieval - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/retrieval?utm_source=openai'), AnnotationURLCitation(end_index=4078, start_index=3989, title='Building RAG with Milvus, vLLM, and Llama 3.1 | Milvus Documentation', type='url_citation', url='https://blog.milvus.io/docs/milvus_rag_with_vllm.md?utm_source=openai'), AnnotationURLCitation(end_index=4646, start_index=4533, title='text-embedding-3-large Model | OpenAI API', type='url_citation', url='https://developers.openai.com/api/docs/models/text-embedding-3-large?utm_source=openai'), AnnotationURLCitation(end_index=4773, start_index=4693, title='Build RAG with Milvus | Milvus Documentation', type='url_citation', url='https://milvus.io/docs/build-rag-with-milvus.md?utm_source=openai'), AnnotationURLCitation(end_index=5448, start_index=5383, title='Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?', type='url_citation', url='https://arxiv.org/abs/2503.21157?utm_source=openai'), AnnotationURLCitation(end_index=5716, start_index=5628, title='Vector Databases Compared: Pinecone vs Weaviate vs Qdrant vs Chroma 2026 | Leaper', type='url_citation', url='https://leaper.dev/blog/vector-databases-compared-2026?utm_source=openai'), AnnotationURLCitation(end_index=6029, start_index=5964, title='LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval', type='url_citation', url='https://arxiv.org/abs/2601.05270?utm_source=openai'), AnnotationURLCitation(end_index=6480, start_index=6341, title='\\u200b\\u200bRAG is dead: why enterprises are shifting to agent-based AI architectures', type='url_citation', url='https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures?utm_source=openai'), AnnotationURLCitation(end_index=6726, start_index=6630, title='New embedding models and API updates | OpenAI', type='url_citation', url='https://openai.com/index/new-embedding-models-and-api-updates/?utm_source=openai'), AnnotationURLCitation(end_index=7022, start_index=6923, title='Retrieval - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/python/langchain/retrieval?utm_source=openai'), AnnotationURLCitation(end_index=7286, start_index=7221, title='Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2602.03689?utm_source=openai'), AnnotationURLCitation(end_index=7543, start_index=7478, title='Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel Multi-Resolution Vector Search', type='url_citation', url='https://arxiv.org/abs/2511.16681?utm_source=openai'), AnnotationURLCitation(end_index=7747, start_index=7682, title='Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?', type='url_citation', url='https://arxiv.org/abs/2503.21157?utm_source=openai'), AnnotationURLCitation(end_index=7996, start_index=7908, title='Vector Databases Compared: Pinecone vs Weaviate vs Qdrant vs Chroma 2026 | Leaper', type='url_citation', url='https://leaper.dev/blog/vector-databases-compared-2026?utm_source=openai'), AnnotationURLCitation(end_index=8224, start_index=8165, title='RAG Use Case: Advanced Vector Search for AI Applications - Qdrant', type='url_citation', url='https://qdrant.tech/rag/?utm_source=openai'), AnnotationURLCitation(end_index=8860, start_index=8755, title='text-embedding-3-large Model | OpenAI API', type='url_citation', url='https://platform.openai.com/docs/models/text-embedding-3-large?utm_source=openai'), AnnotationURLCitation(end_index=9026, start_index=8923, title='Retrieval - Docs by LangChain', type='url_citation', url='https://docs.langchain.com/oss/javascript/langchain/retrieval?utm_source=openai'), AnnotationURLCitation(end_index=9173, start_index=9076, title='Introduction to RAG - LlamaIndex', type='url_citation', url='https://docs.llamaindex.ai/en/stable/understanding/rag/?utm_source=openai'), AnnotationURLCitation(end_index=9328, start_index=9248, title='Build RAG with Milvus | Milvus Documentation', type='url_citation', url='https://milvus.io/docs/build-rag-with-milvus.md?utm_source=openai'), AnnotationURLCitation(end_index=9436, start_index=9377, title='RAG Use Case: Advanced Vector Search for AI Applications - Qdrant', type='url_citation', url='https://qdrant.tech/rag/?utm_source=openai'), AnnotationURLCitation(end_index=9643, start_index=9578, title='Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation', type='url_citation', url='https://arxiv.org/abs/2602.03689?utm_source=openai'), AnnotationURLCitation(end_index=9874, start_index=9724, title='7 Best Practices for RAG Implementation That Actually Improve Your AI Results | ChatRAG Blog', type='url_citation', url='https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai')], text='Short answer: build a modular pipeline that (1) embeds and stores your knowledge in a vector store, (2) retrieves with a hybrid/re-ranked retriever, (3) conditions an LLM with the retrieved passages using a controlled prompting pattern, and (4) monitors/validates outputs and updates the index. Below is a practical, up‑to‑date (Feb 2026) checklist, recommended components, a minimal code pattern, and pointers to advanced techniques and references.\\n\\nQuick checklist (practical order)\\n- Decide scope & safety: which sources, access controls, redaction, and retention policies. (Security is a first‑class concern for RAG.) ([techradar.com](https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures?utm_source=openai))  \\n- Ingest and chunk documents using semantic-aware chunking (500–1000 tokens, or semantic boundaries; store source metadata and version/timestamps). ([chatrag.ai](https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai))  \\n- Compute embeddings with a modern, high-quality model (e.g., OpenAI text-embedding-3-* or a comparable vendor/local model) and store them in a vector DB. ([platform.openai.com](https://platform.openai.com/docs/models/text-embedding-3-large?utm_source=openai))  \\n- Retrieval: use hybrid search (BM25/keyword + dense embeddings) and apply a fast initial ranking (k=10–50). ([morphik.ai](https://www.morphik.ai/blog/retrieval-augmented-generation-strategies?utm_source=openai))  \\n- Rerank: apply a cross-encoder or generator-feedback reranker to pick the best 3–5 passages to send to the LLM. Reranking substantially improves precision and lowers hallucinations. ([arxiv.org](https://arxiv.org/abs/2602.03689?utm_source=openai))  \\n- Prompting & generation: pass only the selected passages + a strict instruction for the model to cite or only use provided sources; include a “verifier” step if necessary. ([help.openai.com](https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts%3F.iso?utm_source=openai))  \\n- Post-check/validation: use an automated answer-checker (LLM-as-judge, specialized hallucination detectors) and human-in-the-loop for high-risk outputs. ([arxiv.org](https://arxiv.org/abs/2503.21157?utm_source=openai))  \\n- Monitoring & feedback loop: track retrieval quality, answer correctness, latency, and user feedback; use that data to retrain or tune retrievers/rerankers. ([chatrag.ai](https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai))\\n\\nRecommended components & why\\n- Embeddings: text-embedding-3-large (or text-embedding-3-small for cost-sensitive workloads). Newer v3 embeddings give much higher semantic performance and let you shorten dimensionality if needed. ([openai.com](https://openai.com/index/new-embedding-models-and-api-updates/?utm_source=openai))  \\n- Vector DB: choose by scale / ops preferences — Qdrant or Milvus are popular self-host options, Pinecone for managed service, Chroma for rapid prototyping. Consider filtering and multi-vector support. ([qdrant.tech](https://qdrant.tech/rag/?utm_source=openai))  \\n- Retrieval stack: hybrid retrieval (BM25 + dense) + reranker (cross-encoder or RL/feedback-based reranker) to reduce hallucinations and improve precision. ([morphik.ai](https://www.morphik.ai/blog/retrieval-augmented-generation-strategies?utm_source=openai))  \\n- Orchestration / libraries: LangChain or LlamaIndex (interfaces for loaders, splitters, retrievers, chains/agents), plus vector DB adapters. They implement common RAG patterns (2‑step RAG, agentic/hybrid RAG). ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/retrieval?utm_source=openai))  \\n- LLMs: cloud models (OpenAI, Anthropic, etc.) or local LLMs (Llama 3.x with vLLM for on‑prem inference) depending on latency, cost, and data control requirements. ([blog.milvus.io](https://blog.milvus.io/docs/milvus_rag_with_vllm.md?utm_source=openai))\\n\\nMinimal “2‑step RAG” pattern (conceptual / short Python sketch)\\n- Ingest → split → embed → upsert to vector DB (include metadata like doc_id, source, date).  \\n- Query → (optional) rewrite/clarify query → retrieve top-K from hybrid retriever → rerank → select top-M passages → prompt LLM with instruction + passages → post-check/return answer with sources.\\n\\nExample (pseudocode, LangChain style):\\n- Build embeddings: use text‑embedding‑3‑large (OpenAI). ([developers.openai.com](https://developers.openai.com/api/docs/models/text-embedding-3-large?utm_source=openai))  \\n- Store in vector DB (e.g., Milvus/Qdrant). ([milvus.io](https://milvus.io/docs/build-rag-with-milvus.md?utm_source=openai))  \\n- Retrieve & rerank, then call LLM with strict prompt \"ONLY use the sections below; if you cannot answer, say \\'I don\\'t know\\' and list sources.\"\\n\\nIf you want an exact, runnable example (LangChain + OpenAI + Milvus), I can paste a ready-to-run notebook; say which stack you prefer (OpenAI vs local LLM, Milvus vs Qdrant vs Pinecone).\\n\\nKey production considerations (common pitfalls & mitigation)\\n- Hallucinations: reduce by reranking, strict prompt constraints, citation of sources, and automated verifier/judge models. Expect retrieval quality to explain most of answer quality—spend time improving the \"R\". ([arxiv.org](https://arxiv.org/abs/2503.21157?utm_source=openai))  \\n- Latency: cache frequent queries, tune vector DB indexes, limit what you send to the LLM (context window and number of passages), or use smaller/faster LLMs for lower latency. ([leaper.dev](https://leaper.dev/blog/vector-databases-compared-2026?utm_source=openai))  \\n- Freshness and versioning: use a live-update or hot/cold strategy (hot indices for current content, cold storage for history) when documents change frequently; store timestamps and support point‑in‑time retrieval if you need auditable answers. ([arxiv.org](https://arxiv.org/abs/2601.05270?utm_source=openai))  \\n- Security & access control: centralizing content into vectors can bypass original access controls—implement metadata filters, per-query authorization checks, and consider agentic approaches that query sources at runtime (instead of copying sensitive data into a central vector DB) if compliance requires it. ([techradar.com](https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures?utm_source=openai))  \\n- Cost control: batch embedding calls, shorten embeddings if your vector store has dimension limits, and pick small/large embedding models by SLA. ([openai.com](https://openai.com/index/new-embedding-models-and-api-updates/?utm_source=openai))\\n\\nAdvanced / trending topics (2024–2026)\\n- Agentic RAG: agents decide when/how to retrieve and which tools to call; useful for multi-step research tasks but higher complexity and variable latency. ([docs.langchain.com](https://docs.langchain.com/oss/python/langchain/retrieval?utm_source=openai))  \\n- Reranker policies that optimize the generator’s “Goldilocks Zone” (not too trivial, not too hard) via learned/rLHF style feedback — recent work shows big robustness gains (BAR‑RAG and similar). ([arxiv.org](https://arxiv.org/abs/2602.03689?utm_source=openai))  \\n- Hybrid & multi-resolution indexing: dynamically changing index resolution by query type to balance speed and semantic granularity. This is active research and useful at very large scale. ([arxiv.org](https://arxiv.org/abs/2511.16681?utm_source=openai))  \\n- Real-time hallucination detectors and LLM-as-judge for post-hoc verification; combine with human-in-the-loop for high-stakes outputs. ([arxiv.org](https://arxiv.org/abs/2503.21157?utm_source=openai))\\n\\nIf you’re starting from scratch: short recommended path\\n1. Prototype: Chroma (local) + OpenAI text‑embedding‑3‑small + LangChain + OpenAI LLM. Fast iteration. ([leaper.dev](https://leaper.dev/blog/vector-databases-compared-2026?utm_source=openai))  \\n2. If you go production: migrate to Qdrant or Milvus (or Pinecone managed), add a cross-encoder reranker, add monitoring & feedback loops, and harden auth/redaction. ([qdrant.tech](https://qdrant.tech/rag/?utm_source=openai))\\n\\nWantables — what I can do next for you\\n- Provide a concrete end-to-end notebook (LangChain or LlamaIndex) targeted to your stack (OpenAI vs local LLM; Milvus vs Qdrant vs Pinecone).  \\n- Help pick chunking parameters and run a small retrieval evaluation on a sample of your docs.  \\n- Produce a production checklist (security, monitoring metrics, SLOs) tailored to regulated or internal‑use cases.\\n\\nReferences (selected, current references used above)\\n- OpenAI: Embeddings / Retrieval docs (text-embedding-3-large, Retrieval API). ([platform.openai.com](https://platform.openai.com/docs/models/text-embedding-3-large?utm_source=openai))  \\n- LangChain docs: retrieval/RAG architectures and patterns. ([docs.langchain.com](https://docs.langchain.com/oss/javascript/langchain/retrieval?utm_source=openai))  \\n- LlamaIndex docs: RAG tutorials and concepts. ([docs.llamaindex.ai](https://docs.llamaindex.ai/en/stable/understanding/rag/?utm_source=openai))  \\n- Milvus: RAG tutorials and examples (Milvus + LlamaIndex / LangChain). ([milvus.io](https://milvus.io/docs/build-rag-with-milvus.md?utm_source=openai))  \\n- Qdrant: RAG use-case and performance notes. ([qdrant.tech](https://qdrant.tech/rag/?utm_source=openai))  \\n- Research: BAR‑RAG (boundary-aware reranker for robust RAG, Feb 2026); Hybrid retrieval and multi-resolution indexing papers (2024–2026). ([arxiv.org](https://arxiv.org/abs/2602.03689?utm_source=openai))  \\n- Practical blogs/guides (2025–2026) summarizing best practices and pitfalls. ([chatrag.ai](https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results?utm_source=openai))\\n\\nIf you want, tell me:\\n- Your preferred stack (OpenAI vs local LLM; Milvus vs Qdrant vs Pinecone), and whether you care more about latency, cost, or strict data control — I’ll produce a concrete starter notebook and a production checklist tailored to that choice.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in response.output:\n",
    "    print(m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ff016ae-a92b-4279-b604-0d84b995d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = response.output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8cfd9df-84f3-483f-9d2f-63a728fa409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ActionSearchSource(type='url', url='https://arxiv.org/abs/2602.03689'),\n",
       " ActionSearchSource(type='url', url='https://arxiv.org/abs/2509.25669'),\n",
       " ActionSearchSource(type='url', url='https://arxiv.org/abs/2504.05324'),\n",
       " ActionSearchSource(type='url', url='https://arxiv.org/abs/2503.21157'),\n",
       " ActionSearchSource(type='url', url='https://www.dxtalks.com/blog/news-2/retrieval-augmented-generation-835'),\n",
       " ActionSearchSource(type='url', url='https://jishulabs.com/blog/rag-retrieval-augmented-generation-guide-2026'),\n",
       " ActionSearchSource(type='url', url='https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures'),\n",
       " ActionSearchSource(type='url', url='https://www.chatrag.ai/blog/2026-02-06-7-best-practices-for-rag-implementation-that-actually-improve-your-ai-results'),\n",
       " ActionSearchSource(type='url', url='https://medium.com/%40globalbizoutlook/rag-models-complete-guide-to-retrieval-augmented-generation-for-enterprise-ai-in-2026-741e3b39a7ca'),\n",
       " ActionSearchSource(type='url', url='https://latestfromtechguy.com/article/rag-best-practices-2026'),\n",
       " ActionSearchSource(type='url', url='https://www.emergentmind.com/articles/2407.01219'),\n",
       " ActionSearchSource(type='url', url='https://www.morphik.ai/blog/retrieval-augmented-generation-strategies')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.action.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c29198-7d8b-4a2e-a77a-3a245c26894b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=20937, input_tokens_details=InputTokensDetails(cached_tokens=3712), output_tokens=3506, output_tokens_details=OutputTokensDetails(reasoning_tokens=1152), total_tokens=24443)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a18b2-b850-41fa-b0e0-40193170983e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
