{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e221137a-4154-4099-b4b2-62d52c28760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f1ffc0-7432-43dc-a1db-da5d25ade17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x240b47d1160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from gitsource import GithubRepositoryDataReader, chunk_documents\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "\n",
    "reader = GithubRepositoryDataReader(\n",
    "    repo_owner=\"evidentlyai\",\n",
    "    repo_name=\"docs\",\n",
    "    allowed_extensions={\"md\", \"mdx\"},\n",
    ")\n",
    "files = reader.read()\n",
    "\n",
    "parsed_docs = [doc.parse() for doc in files]\n",
    "chunked_docs = chunk_documents(parsed_docs, size=3000, step=1500)\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"title\", \"description\", \"content\"],\n",
    "    keyword_fields=[\"filename\"]\n",
    ")\n",
    "index.fit(chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1db821d-6f07-4feb-bc3c-3e17ad86cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        num_results=5\n",
    "    )\n",
    "    return results\n",
    "\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the documentation database for relevant results based on a query string.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query to look up in the index\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"query\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ae39d9-b173-4d1a-ade6-952b84cae4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I create a dahsbord in Evidently?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfee6b1b-6356-4aa1-90f5-642d83f30adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, llm_client, model, instructions, tools, output_type=None):\n",
    "        self.llm_client = llm_client\n",
    "        self.model = model\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools\n",
    "\n",
    "    def make_call(self, tool_call):\n",
    "        arguments = json.loads(tool_call.arguments)\n",
    "        name = tool_call.name\n",
    "    \n",
    "        if name == 'search':\n",
    "            result = search(**arguments)\n",
    "        elif name == 'add_entry':\n",
    "            result = add_entry(**arguments)\n",
    "        else:\n",
    "            result = 'not found tool \"{name}\"'\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"output\": json.dumps(result),\n",
    "        }   \n",
    "\n",
    "    def loop(self, user_prompt, message_history=None):\n",
    "        if not message_history:\n",
    "            message_history = [\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "            ]\n",
    "            \n",
    "        message_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        iteration_number = 0\n",
    "    \n",
    "        while True:\n",
    "            response = self.llm_client.responses.create(\n",
    "                model=self.model,\n",
    "                input=message_history,\n",
    "                tools=self.tools,\n",
    "            )\n",
    "        \n",
    "            print(f'iteraration number {iteration_number}...') \n",
    "            message_history.extend(response.output)\n",
    "        \n",
    "            has_function_calls = False\n",
    "        \n",
    "            for message in response.output:\n",
    "                if message.type == 'function_call':\n",
    "                    print(f'executing {message.name}({message.arguments})...')\n",
    "                    tool_call_output = self.make_call(message)\n",
    "                    message_history.append(tool_call_output)\n",
    "                    has_function_calls = True\n",
    "        \n",
    "                if message.type == 'message':\n",
    "                    text = message.content[0].text\n",
    "                    print('ASSISTANT:', text)\n",
    "        \n",
    "            iteration_number = iteration_number + 1\n",
    "            print()\n",
    "            \n",
    "            if not has_function_calls:\n",
    "                break\n",
    "\n",
    "        return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b2cade-c1ed-4e86-a53b-3283a771bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    This model provides a structured answer with metadata about the response,\n",
    "    including confidence, categorization, and follow-up suggestions.\n",
    "    \"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"The main answer to the user's question in markdown\")\n",
    "    found_answer: bool = Field(description=\"True if relevant information was found in the documentation\")\n",
    "    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0 indicating how certain the answer is\")\n",
    "    confidence_explanation: str = Field(description=\"Explanation about the confidence level\")\n",
    "    answer_type: Literal[\"how-to\", \"explanation\", \"troubleshooting\", \"comparison\", \"reference\"] = Field(description=\"The category of the answer\")\n",
    "    followup_questions: list[str] = Field(description=\"Suggested follow-up questions the user might want to ask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c07e2e81-82ed-4199-8803-8d4cc9d36e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a documentation assistant. \n",
    "\n",
    "Answer the user question using the documentation knowledge base\n",
    "\n",
    "Make 3 iterations:\n",
    "\n",
    "1) in the first iteration, perform one search\n",
    "2) in the second interation, analyze the results from the previous search\n",
    "   and perform 2 more searches\n",
    "3) synthesise the results into the output\n",
    "\n",
    "Stop after 3 iterations\n",
    "\n",
    "Use only facts from the knowledge base when answering.\n",
    "If you cannot find the answer, inform the user.\n",
    "\n",
    "Our knowledge base is entirely about Evidently, so you don't need to \n",
    "include the word 'evidently' in search results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a23587a-ab3f-4f87-a1d5-02544ebbc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleStructuredAgent:\n",
    "\n",
    "    def __init__(self, llm_client, model, instructions, tools, output_type=None):\n",
    "        self.llm_client = llm_client\n",
    "        self.model = model\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools\n",
    "        self.output_type = output_type\n",
    "\n",
    "    def make_call(self, tool_call):\n",
    "        arguments = json.loads(tool_call.arguments)\n",
    "        name = tool_call.name\n",
    "    \n",
    "        if name == 'search':\n",
    "            result = search(**arguments)\n",
    "        elif name == 'add_entry':\n",
    "            result = add_entry(**arguments)\n",
    "        else:\n",
    "            result = 'not found tool \"{name}\"'\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"output\": json.dumps(result),\n",
    "        }   \n",
    "\n",
    "    def loop(self, user_prompt, message_history=None):\n",
    "        if not message_history:\n",
    "            message_history = [\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "            ]\n",
    "            \n",
    "        message_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        iteration_number = 0\n",
    "    \n",
    "        while True:\n",
    "            if output_type:\n",
    "                response = self.llm_client.responses.parse(\n",
    "                    model=self.model,\n",
    "                    input=message_history,\n",
    "                    tools=self.tools,\n",
    "                    text_format=self.output_type\n",
    "                )\n",
    "            else:\n",
    "                response = self.llm_client.responses.create(\n",
    "                    model=self.model,\n",
    "                    input=message_history,\n",
    "                    tools=self.tools,\n",
    "                )\n",
    "        \n",
    "            print(f'iteraration number {iteration_number}...') \n",
    "            message_history.extend(response.output)\n",
    "        \n",
    "            has_function_calls = False\n",
    "        \n",
    "            for message in response.output:\n",
    "                if message.type == 'function_call':\n",
    "                    print(f'executing {message.name}({message.arguments})...')\n",
    "                    tool_call_output = self.make_call(message)\n",
    "                    message_history.append(tool_call_output)\n",
    "                    has_function_calls = True\n",
    "        \n",
    "                if message.type == 'message':\n",
    "                    text = message.content[0].text\n",
    "                    print('ASSISTANT:', text)\n",
    "        \n",
    "            iteration_number = iteration_number + 1\n",
    "            print()\n",
    "            \n",
    "            if not has_function_calls:\n",
    "                break\n",
    "\n",
    "        return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "875c4133-2a9d-4c30-be43-f6069906b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = SimpleStructuredAgent(\n",
    "    llm_client=OpenAI(),\n",
    "    model='gpt-4o-mini',\n",
    "    instructions=instructions,\n",
    "    tools=[search_tool],\n",
    "    output_type=RAGResponse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce8deacf-13eb-41b2-a23a-e3de6758a95d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m messages = \u001b[43msimple_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevidently adshboards\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mSimpleStructuredAgent.loop\u001b[39m\u001b[34m(self, user_prompt, message_history)\u001b[39m\n\u001b[32m     35\u001b[39m iteration_number = \u001b[32m0\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43moutput_type\u001b[49m:\n\u001b[32m     39\u001b[39m         response = \u001b[38;5;28mself\u001b[39m.llm_client.responses.parse(\n\u001b[32m     40\u001b[39m             model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m     41\u001b[39m             \u001b[38;5;28minput\u001b[39m=message_history,\n\u001b[32m     42\u001b[39m             tools=\u001b[38;5;28mself\u001b[39m.tools,\n\u001b[32m     43\u001b[39m             text_format=\u001b[38;5;28mself\u001b[39m.output_type\n\u001b[32m     44\u001b[39m         )\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'output_type' is not defined"
     ]
    }
   ],
   "source": [
    "messages = simple_agent.loop('evidently adshboards') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794763ec-1d17-4f1b-9f1f-13403f08ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, llm_client, model, instructions, tools):\n",
    "        self.llm_client = llm_client\n",
    "        self.model = model\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools\n",
    "\n",
    "    def make_call(self, tool_call):\n",
    "        arguments = json.loads(tool_call.arguments)\n",
    "        name = tool_call.name\n",
    "    \n",
    "        if name == 'search':\n",
    "            result = search(**arguments)\n",
    "        elif name == 'add_entry':\n",
    "            result = add_entry(**arguments)\n",
    "        else:\n",
    "            result = 'not found tool \"{name}\"'\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"output\": json.dumps(result),\n",
    "        }   \n",
    "\n",
    "    def loop(self, user_prompt, message_history=None):\n",
    "        if not message_history:\n",
    "            message_history = [\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "            ]\n",
    "            \n",
    "        message_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        iteration_number = 0\n",
    "    \n",
    "        while True:\n",
    "            response = self.llm_client.responses.create(\n",
    "                model=self.model,\n",
    "                input=message_history,\n",
    "                tools=self.tools,\n",
    "            )\n",
    "        \n",
    "            print(f'iteraration number {iteration_number}...') \n",
    "            message_history.extend(response.output)\n",
    "        \n",
    "            has_function_calls = False\n",
    "        \n",
    "            for message in response.output:\n",
    "                if message.type == 'function_call':\n",
    "                    print(f'executing {message.name}({message.arguments})...')\n",
    "                    tool_call_output = self.make_call(message)\n",
    "                    message_history.append(tool_call_output)\n",
    "                    has_function_calls = True\n",
    "        \n",
    "                if message.type == 'message':\n",
    "                    text = message.content[0].text\n",
    "                    print('ASSISTANT:', text)\n",
    "        \n",
    "            iteration_number = iteration_number + 1\n",
    "            print()\n",
    "            \n",
    "            if not has_function_calls:\n",
    "                break\n",
    "\n",
    "        return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953119c-784b-4b06-9231-21d6f28418f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e5930-2fef-45e1-8f72-36c69fbc2f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "583af8e6-da83-4069-89a1-abbaf9ad48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a documentation assistant. \n",
    "\n",
    "Answer the user question using the documentation knowledge base\n",
    "\n",
    "Make 3 iterations:\n",
    "\n",
    "1) in the first iteration, perform one search\n",
    "2) in the second interation, analyze the results from the previous search\n",
    "   and perform 2 more searches\n",
    "3) synthesise the results into the output\n",
    "\n",
    "IMPORTANT: at each step, give an explanation of why you want to perform \n",
    "search for this particular search query. It should be 2-3 sentences explaining\n",
    "the logic of your decision.\n",
    "\n",
    "Use only facts from the knowledge base when answering.\n",
    "If you cannot find the answer, inform the user.\n",
    "\n",
    "Our knowledge base is entirely about Evidently, so you don't need to \n",
    "include the word 'evidently' in search results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "032340c1-80ba-4d23-a5f4-130acb53010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    llm_client=OpenAI(),\n",
    "    model='gpt-4o-mini',\n",
    "    instructions=instructions,\n",
    "    tools=[search_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b75c8df5-67ab-44f7-8e66-2d8763cde7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteraration number 0...\n",
      "ASSISTANT: I will start by searching for \"dashboards\" to understand the available features related to this topic. This term is broad and will help identify specific tools, functionalities, or components related to dashboards that may be useful for your query.\n",
      "\n",
      "Let's perform the search now.\n",
      "executing search({\"query\":\"dashboards\"})...\n",
      "\n",
      "iteraration number 1...\n",
      "ASSISTANT: The search results provided a wealth of information about how dashboards function within the system. They describe how to create and manage dashboards, add panels, and organize data through tabs. Key highlights include:\n",
      "\n",
      "1. **Dashboard Overview**: A dashboard is essential for visualizing evaluation results over time and tracking the performance of an AI application.\n",
      "\n",
      "2. **Panels and Tabs**: You can add multiple panels to a dashboard to display various metrics, and you can organize these panels into different tabs for better clarity.\n",
      "\n",
      "3. **Adding Panels**: Panels can be added both through a user interface (UI) in no-code environments or by using a Python API. Each panel can represent a different metric or visualization type (e.g., counters, plots).\n",
      "\n",
      "Now that I have a foundational understanding, I'll conduct two more searches. The first will focus on \"dashboard management,\" as this may uncover specific practices and tips on maintaining and organizing dashboards effectively. The second search will look into \"adding panels,\" to gather more detailed instructions on how to implement specific metrics and customize panel types. \n",
      "\n",
      "Let's perform these searches.\n",
      "executing search({\"query\":\"dashboard management\"})...\n",
      "executing search({\"query\":\"adding panels\"})...\n",
      "\n",
      "iteraration number 2...\n",
      "ASSISTANT: From the additional searches, I've gathered detailed information about dashboard management and adding panels:\n",
      "\n",
      "### Dashboard Management\n",
      "Dashboards can be efficiently managed through a variety of functionalities:\n",
      "\n",
      "1. **Adding Tabs**: You can create new tabs to organize your panels. For example, using Python:\n",
      "   ```python\n",
      "   project.dashboard.add_tab(\"Another Tab\")\n",
      "   ```\n",
      "   If creating a panel in a non-existent tab, the tab will be created automatically.\n",
      "\n",
      "2. **Deleting Tabs and Panels**: Tabs and panels can be easily deleted through:\n",
      "   ```python\n",
      "   project.dashboard.delete_tab(\"Another Tab\")\n",
      "   project.dashboard.delete_panel(\"Dashboard title\", \"My new tab\")\n",
      "   ```\n",
      "\n",
      "3. **Clearing the Dashboard**: You can clear all tabs and panels without affecting the underlying reports:\n",
      "   ```python\n",
      "   project.dashboard.clear_dashboard()\n",
      "   ```\n",
      "\n",
      "### Adding Panels\n",
      "Adding panels involves both user interface and Python API approaches. Key points include:\n",
      "\n",
      "1. **Panel Types**:\n",
      "   - **Text Panels** for titles and descriptions.\n",
      "   - **Counter Panels** to display single values, like counts or averages.\n",
      "   - **Plot Panels** such as line and bar charts to visualize data over time.\n",
      "   \n",
      "   For example:\n",
      "   ```python\n",
      "   project.dashboard.add_panel(\n",
      "       DashboardPanelPlot(\n",
      "           title=\"Row count\",\n",
      "           size=\"half\",\n",
      "           values=[PanelMetric(legend=\"Row count\", metric=\"RowCount\")],\n",
      "           plot_params={\"plot_type\": \"counter\"}\n",
      "       ),\n",
      "       tab=\"My tab\"\n",
      "   )\n",
      "   ```\n",
      "\n",
      "2. **Configuration Options**: Each panel can be customized with various parameters such as title, size, and the specific metrics you want to visualize. Hereâ€™s a brief overview:\n",
      "   - **Title**: The name of your panel.\n",
      "   - **Size**: Defines if it should take full or half width.\n",
      "   - **Values**: Specifies the metrics to be displayed.\n",
      "\n",
      "3. **Multiple Data Sources**: One panel can represent multiple values, allowing complex visualizations like multi-series line graphs.\n",
      "\n",
      "### Next Steps\n",
      "To effectively use dashboards, consider setting up your panels according to metrics you're interested in tracking. Utilizing both user interface elements and scripting through Python can streamline your workflow. If you need any specific instruction on these processes, feel free to ask!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = agent.loop('evidently adshboards') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f27d849-c23c-401e-a19a-9f87ea079724",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.parse(\n",
    "    model=agent.model,\n",
    "    input=messages,\n",
    "    text_format=RAGResponse\n",
    ")\n",
    "\n",
    "rag_response = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43db5253-07e5-4029-9d22-4822cf0471b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0f8dd32-48bf-45af-9ef4-812e56993e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredAgent1(Agent):\n",
    "\n",
    "    def __init__(self, llm_client, model, instructions, tools, output_type):\n",
    "        super().__init__(llm_client, model, instructions, tools)\n",
    "        self.output_type = output_type\n",
    "        \n",
    "    def structured_loop(self, user_prompt, message_history=None):\n",
    "        message_history = self.loop(user_prompt, message_history)\n",
    "        response = self.llm_client.responses.parse(\n",
    "            model=self.model,\n",
    "            input=message_history,\n",
    "            text_format=self.output_type\n",
    "        )\n",
    "    \n",
    "        output = response.output_parsed\n",
    "        return message_history, output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfab46-96af-48e0-9a51-16a25b81ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_agent_1 = StructuredAgent1(\n",
    "    llm_client=OpenAI(),\n",
    "    model='gpt-4o-mini',\n",
    "    instructions=instructions,\n",
    "    tools=[search_tool],\n",
    "    output_type=RAGResponse\n",
    ")\n",
    "\n",
    "_, output = structure_agent_1.structured_loop('bashboards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f52f9a85-c70c-46cf-8a09-348a49ca58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Overview of Dashboards\n",
      "- **What is a Dashboard?**: A dashboard provides a clear view of your AI application performance, helping track evaluation results across multiple experiments or live production quality over time.\n",
      "- **Tabs**: Each project has its own dashboard, organized into tabs, which can be added or customized, providing a logical structure to your panels.\n",
      "\n",
      "### Creating and Managing Panels\n",
      "1. **Panel Types**: You can add several types of panels such as:\n",
      "    - **Text Panels**: For displaying titles or notes.\n",
      "    - **Counter Panels**: For showing metrics with optional text.\n",
      "    - **Charts**: Including pie charts, bar plots, and line plots to visualize data.\n",
      "\n",
      "2. **Adding Panels**: There are two main ways to add panels:\n",
      "    - **User Interface**: Enter \"Edit\" mode, click \"Add Panel,\" and follow prompts to configure.\n",
      "    - **Python API**: Using methods to programmatically create panels as per your requirements.\n",
      "\n",
      "3. **Configuration Options**: While adding a panel, you can specify:\n",
      "    - **Title & Subtitle**: What will be displayed on the panel.\n",
      "    - **Size**: Options are full or half width.\n",
      "    - **Metrics**: Define specific metrics to plot. You can filter these by tags or other parameters such as columns or value types.\n",
      "    - **Plot Parameters**: Change how data is visualized, including types of plots/information types to include.\n",
      "\n",
      "### Example Snippets for Creating Panels\n",
      "- **To Add a Counter Panel**:\n",
      "    ```python\n",
      "    project.dashboard.add_panel(\n",
      "        DashboardPanelPlot(\n",
      "            title=\"Row count\",\n",
      "            subtitle=\"Total evaluations over time.\",\n",
      "            size=\"half\",\n",
      "            values=[PanelMetric(legend=\"Row count\", metric=\"RowCount\")],\n",
      "            plot_params={\"plot_type\": \"counter\", \"aggregation\": \"sum\"},\n",
      "        ),\n",
      "        tab=\"My Tab\",\n",
      "    )\n",
      "    ```\n",
      "- **To Create a Pie Chart**:\n",
      "    ```python\n",
      "    project.dashboard.add_panel(\n",
      "        DashboardPanelPlot(\n",
      "            title=\"Row count\",\n",
      "            subtitle=\"Total evaluations over time.\",\n",
      "            size=\"half\",\n",
      "            values=[PanelMetric(legend=\"Row count\", metric=\"RowCount\")],\n",
      "            plot_params={\"plot_type\": \"pie\", \"aggregation\": \"sum\"},\n",
      "        ),\n",
      "        tab=\"My Tab\",\n",
      "    )\n",
      "    ```\n",
      "\n",
      "### Summary\n",
      "Dashboards are powerful tools for visualizing metrics connected to your AI applications. You can customize and manage them effectively through both the user interface and programmatically using Python. For any further specific questions or details, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(output.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d20a2b-4116-4abf-8f2c-000340050b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c18bca4-0711-467f-8a35-5d7d9a4ac021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_result(result: RAGResponse):\n",
    "    return 'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b1692-ec27-46fd-9771-84035c111beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = RAGResponse.model_json_schema()\n",
    "schema[\"type\"] = \"object\"\n",
    "schema[\"additionalProperties\"] = False\n",
    "\n",
    "structure_result_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"structure_result\",\n",
    "    \"description\": \"Call this function when you're ready to show the final result as structured data.\",\n",
    "    \"strict\": True,\n",
    "    \"parameters\": schema,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc698885-10a4-4c60-b6f0-c13f4380a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=agent.model,\n",
    "    input=messages,\n",
    "    tools=[structure_result_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b87f521-06e2-4cb6-9787-4140378642f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = json.loads(response.output[0].arguments)\n",
    "result = RAGResponse.model_validate(result_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "792e296e-9368-401f-9624-59047c501366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_tool(output_type, name=\"structure_result\"):\n",
    "    schema = output_type.model_json_schema()\n",
    "    schema[\"type\"] = \"object\"\n",
    "    schema[\"additionalProperties\"] = False\n",
    "    \n",
    "    structure_result_tool = {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": name,\n",
    "        \"description\": \"Call this function when you're ready to show the final result as structured data.\",\n",
    "        \"strict\": True,\n",
    "        \"parameters\": schema,\n",
    "    }\n",
    "\n",
    "    return structure_result_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46bb84ba-e2d1-4014-a6a3-6753de1715bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredAgent2:\n",
    "\n",
    "    FAKE_TOOL_NAME = 'structure_result'\n",
    "    \n",
    "    def __init__(self, llm_client, model, instructions, tools, output_type):\n",
    "        self.llm_client = llm_client\n",
    "        self.model = model\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools + [create_fake_tool(output_type, self.FAKE_TOOL_NAME)]\n",
    "        self.output_type = output_type\n",
    "\n",
    "    def make_call(self, tool_call):\n",
    "        arguments = json.loads(tool_call.arguments)\n",
    "        name = tool_call.name\n",
    "    \n",
    "        if name == 'search':\n",
    "            result = search(**arguments)\n",
    "        elif name == 'add_entry':\n",
    "            result = add_entry(**arguments)\n",
    "        else:\n",
    "            result = 'not found tool \"{name}\"'\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"output\": json.dumps(result),\n",
    "        }   \n",
    "\n",
    "    def loop(self, user_prompt, message_history=None):\n",
    "        if not message_history:\n",
    "            message_history = [\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "            ]\n",
    "            \n",
    "        message_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        iteration_number = 0\n",
    "    \n",
    "        while True:\n",
    "            response = self.llm_client.responses.create(\n",
    "                model=self.model,\n",
    "                input=message_history,\n",
    "                tools=self.tools,\n",
    "            )\n",
    "        \n",
    "            print(f'iteraration number {iteration_number}...') \n",
    "            message_history.extend(response.output)\n",
    "        \n",
    "            output = None\n",
    "\n",
    "            for message in response.output:\n",
    "                if message.type == 'function_call':\n",
    "                    print(f'executing {message.name}({message.arguments})...')\n",
    "                    if message.name == self.FAKE_TOOL_NAME:\n",
    "                        output_ready = True\n",
    "                        output_json = json.loads(message.arguments)\n",
    "                        output = self.output_type.model_validate(output_json)\n",
    "                        continue\n",
    "\n",
    "                    tool_call_output = self.make_call(message)\n",
    "                    message_history.append(tool_call_output)\n",
    "        \n",
    "                if message.type == 'message':\n",
    "                    text = message.content[0].text\n",
    "                    print('ASSISTANT:', text)\n",
    "        \n",
    "            iteration_number = iteration_number + 1\n",
    "            print()\n",
    "            \n",
    "            if output:\n",
    "                break\n",
    "\n",
    "        return message_history, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a754e-8a45-438c-adef-783d75d04352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "460d38b5-a99a-4ffd-b680-b7b8c7ef1b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteraration number 0...\n",
      "ASSISTANT: It seems like you might be looking for information related to dashboards. Since this is a broad topic, I want to perform an initial search to see if there's any relevant documentation regarding dashboards, their creation, features, or usage. This will help me understand the context and narrow down the search in the subsequent steps.\n",
      "\n",
      "I'll proceed with the first search for \"dashboards.\"\n",
      "executing search({\"query\":\"dashboards\"})...\n",
      "\n",
      "iteraration number 1...\n",
      "ASSISTANT: The first search returned several relevant documents related to dashboards, including how to add and manage dashboard panels, the role of dashboards in tracking evaluation results, and ways to organize them using tabs. This foundational information indicates that dashboards are central to visualizing evaluation results and organizing data.\n",
      "\n",
      "Now, to refine my understanding and gather more specific information, I will conduct two additional searches: one for \"dashboard panels\" to learn more about the specific elements within dashboards, and another for \"dashboard management\" to find out about organizing and managing these dashboards efficiently. This will create a comprehensive understanding of how dashboards function and how to utilize them effectively.\n",
      "\n",
      "I'll perform these two additional searches now.\n",
      "executing search({\"query\":\"dashboard panels\"})...\n",
      "executing search({\"query\":\"dashboard management\"})...\n",
      "\n",
      "iteraration number 2...\n",
      "ASSISTANT: After performing the searches for \"dashboard panels\" and \"dashboard management,\" I've gathered a comprehensive set of information regarding how to effectively create, manage, and utilize dashboards.\n",
      "\n",
      "### Overview of Dashboards\n",
      "1. **What are Dashboards?**\n",
      "   - Dashboards provide a visual representation of your evaluation results, allowing you to track performance over time across various projects and experiments. Each project starts with an empty dashboard that you can populate by adding evaluation reports.\n",
      "\n",
      "2. **Creating and Managing Tabs**\n",
      "   - You can add multiple tabs to organize your panels logically within the dashboard. This can be done either through the UI by entering \"Edit\" mode and using the \"+\" button, or programmatically using the Python API with methods like `project.dashboard.add_tab(\"TabName\")`.\n",
      "\n",
      "3. **Adding Panels**\n",
      "   - Panels are the individual visual elements of a dashboard that display metrics. You can add various panel types such as counters, line plots, bar charts, and pie charts. Each panel must reference a specific metric within the reports logged to the project.\n",
      "\n",
      "### Detailed Information on Dashboard Panels\n",
      "- **Panel Types**: You can create text panels for titles, counter panels for numeric values, and various chart types to represent data visually. \n",
      "- **Configuration**:\n",
      "  - **How to add a Panel via UI**:\n",
      "    - Enter \"Edit\" mode, click \"Add Panel\", select the type, configure the metric(s), and save it.\n",
      "  - **How to add a Panel via Python API**:\n",
      "    - Use the `project.dashboard.add_panel` method, specifying parameters such as title, size, and the metrics to display.\n",
      "\n",
      "### Deleting and Modifying Panels\n",
      "- You can delete panels or tabs by entering \"Edit\" mode, hovering over the panel/tab, and selecting the appropriate action. You can also clear the entire dashboard while retaining the underlying reports using `project.dashboard.clear_dashboard()`.\n",
      "\n",
      "### Example Code Snippets for Adding Panels\n",
      "- **Adding a Text Panel**:\n",
      "   ```python\n",
      "   project.dashboard.add_panel(\n",
      "       DashboardPanelPlot(\n",
      "           title=\"Dashboard Title\",\n",
      "           size=\"full\",\n",
      "           values=[],\n",
      "           plot_params={\"plot_type\": \"text\"},\n",
      "       ),\n",
      "       tab=\"My New Tab\",\n",
      "   )\n",
      "   ```\n",
      "\n",
      "- **Adding a Counter Panel**:\n",
      "   ```python\n",
      "   project.dashboard.add_panel(\n",
      "       DashboardPanelPlot(\n",
      "           title=\"Row Count\",\n",
      "           subtitle=\"Total evaluations\",\n",
      "           size=\"half\",\n",
      "           values=[PanelMetric(legend=\"Row Count\", metric=\"RowCount\")],\n",
      "           plot_params={\"plot_type\": \"counter\", \"aggregation\": \"sum\"},\n",
      "       ),\n",
      "       tab=\"My Tab\",\n",
      "   )\n",
      "   ```\n",
      "\n",
      "This synthesized information should provide a solid foundation for creating and managing your dashboards effectively. If you have any more specific queries or need further assistance, feel free to ask!\n",
      "\n",
      "iteraration number 3...\n",
      "executing structure_result({\"answer\":\"### Overview of Dashboards\\n1. **What are Dashboards?**\\n   - Dashboards provide a visual representation of your evaluation results, allowing you to track performance over time across various projects and experiments. Each project starts with an empty dashboard that you can populate by adding evaluation reports.\\n\\n2. **Creating and Managing Tabs**\\n   - You can add multiple tabs to organize your panels logically within the dashboard. This can be done either through the UI by entering \\\"Edit\\\" mode and using the \\\"+\\\" button, or programmatically using the Python API with methods like `project.dashboard.add_tab(\\\"TabName\\\")`.\\n\\n3. **Adding Panels**\\n   - Panels are the individual visual elements of a dashboard that display metrics. You can add various panel types such as counters, line plots, bar charts, and pie charts. Each panel must reference a specific metric within the reports logged to the project.\\n\\n### Detailed Information on Dashboard Panels\\n- **Panel Types**: You can create text panels for titles, counter panels for numeric values, and various chart types to represent data visually. \\n- **Configuration**:\\n  - **How to add a Panel via UI**:\\n    - Enter \\\"Edit\\\" mode, click \\\"Add Panel\\\", select the type, configure the metric(s), and save it.\\n  - **How to add a Panel via Python API**:\\n    - Use the `project.dashboard.add_panel` method, specifying parameters such as title, size, and the metrics to display.\\n\\n### Deleting and Modifying Panels\\n- You can delete panels or tabs by entering \\\"Edit\\\" mode, hovering over the panel/tab, and selecting the appropriate action. You can also clear the entire dashboard while retaining the underlying reports using `project.dashboard.clear_dashboard()`.\\n\\n### Example Code Snippets for Adding Panels\\n- **Adding a Text Panel**:\\n   ```python\\n   project.dashboard.add_panel(\\n       DashboardPanelPlot(\\n           title=\\\"Dashboard Title\\\",\\n           size=\\\"full\\\",\\n           values=[],\\n           plot_params={\\\"plot_type\\\": \\\"text\\\"},\\n       ),\\n       tab=\\\"My New Tab\\\",\\n   )\\n   ```\\n\\n- **Adding a Counter Panel**:\\n   ```python\\n   project.dashboard.add_panel(\\n       DashboardPanelPlot(\\n           title=\\\"Row Count\\\",\\n           subtitle=\\\"Total evaluations\\\",\\n           size=\\\"half\\\",\\n           values=[PanelMetric(legend=\\\"Row Count\\\", metric=\\\"RowCount\\\")],\\n           plot_params={\\\"plot_type\\\": \\\"counter\\\", \\\"aggregation\\\": \\\"sum\\\"},\\n       ),\\n       tab=\\\"My Tab\\\",\\n   )\\n   ```\\n\\nThis synthesized information should provide a solid foundation for creating and managing your dashboards effectively. If you have any more specific queries or need further assistance, feel free to ask!\",\"found_answer\":true,\"confidence\":0.95,\"confidence_explanation\":\"The information provided is directly derived from multiple relevant search results related to dashboards, their management, and the use of panels, ensuring a high degree of accuracy and relevance.\",\"answer_type\":\"how-to\",\"followup_questions\":[\"How do I customize my dashboard further?\",\"What metrics can I display in the dashboard panels?\",\"Is there a way to automate panel updates?\"]})...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structure_agent_2 = StructuredAgent2(\n",
    "    llm_client=OpenAI(),\n",
    "    model='gpt-4o-mini',\n",
    "    instructions=instructions,\n",
    "    tools=[search_tool],\n",
    "    output_type=RAGResponse\n",
    ")\n",
    "\n",
    "_, output = structure_agent_2.loop('bashboards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "869705fd-cb26-480e-8997-5023535e13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Overview of Dashboards\n",
      "1. **What are Dashboards?**\n",
      "   - Dashboards provide a visual representation of your evaluation results, allowing you to track performance over time across various projects and experiments. Each project starts with an empty dashboard that you can populate by adding evaluation reports.\n",
      "\n",
      "2. **Creating and Managing Tabs**\n",
      "   - You can add multiple tabs to organize your panels logically within the dashboard. This can be done either through the UI by entering \"Edit\" mode and using the \"+\" button, or programmatically using the Python API with methods like `project.dashboard.add_tab(\"TabName\")`.\n",
      "\n",
      "3. **Adding Panels**\n",
      "   - Panels are the individual visual elements of a dashboard that display metrics. You can add various panel types such as counters, line plots, bar charts, and pie charts. Each panel must reference a specific metric within the reports logged to the project.\n",
      "\n",
      "### Detailed Information on Dashboard Panels\n",
      "- **Panel Types**: You can create text panels for titles, counter panels for numeric values, and various chart types to represent data visually. \n",
      "- **Configuration**:\n",
      "  - **How to add a Panel via UI**:\n",
      "    - Enter \"Edit\" mode, click \"Add Panel\", select the type, configure the metric(s), and save it.\n",
      "  - **How to add a Panel via Python API**:\n",
      "    - Use the `project.dashboard.add_panel` method, specifying parameters such as title, size, and the metrics to display.\n",
      "\n",
      "### Deleting and Modifying Panels\n",
      "- You can delete panels or tabs by entering \"Edit\" mode, hovering over the panel/tab, and selecting the appropriate action. You can also clear the entire dashboard while retaining the underlying reports using `project.dashboard.clear_dashboard()`.\n",
      "\n",
      "### Example Code Snippets for Adding Panels\n",
      "- **Adding a Text Panel**:\n",
      "   ```python\n",
      "   project.dashboard.add_panel(\n",
      "       DashboardPanelPlot(\n",
      "           title=\"Dashboard Title\",\n",
      "           size=\"full\",\n",
      "           values=[],\n",
      "           plot_params={\"plot_type\": \"text\"},\n",
      "       ),\n",
      "       tab=\"My New Tab\",\n",
      "   )\n",
      "   ```\n",
      "\n",
      "- **Adding a Counter Panel**:\n",
      "   ```python\n",
      "   project.dashboard.add_panel(\n",
      "       DashboardPanelPlot(\n",
      "           title=\"Row Count\",\n",
      "           subtitle=\"Total evaluations\",\n",
      "           size=\"half\",\n",
      "           values=[PanelMetric(legend=\"Row Count\", metric=\"RowCount\")],\n",
      "           plot_params={\"plot_type\": \"counter\", \"aggregation\": \"sum\"},\n",
      "       ),\n",
      "       tab=\"My Tab\",\n",
      "   )\n",
      "   ```\n",
      "\n",
      "This synthesized information should provide a solid foundation for creating and managing your dashboards effectively. If you have any more specific queries or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(output.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f56ee-1987-4c1a-a0ed-bd090b39040c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
