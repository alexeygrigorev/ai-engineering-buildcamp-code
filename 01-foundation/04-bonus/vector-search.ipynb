{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee85b03a-4d41-4ebf-8ae1-cbf7cc7bcd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from minsearch import Index\n",
    "from gitsource import GithubRepositoryDataReader, chunk_documents\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "reader = GithubRepositoryDataReader(\n",
    "    repo_owner=\"evidentlyai\",\n",
    "    repo_name=\"docs\",\n",
    "    allowed_extensions={\"md\", \"mdx\"},\n",
    ")\n",
    "\n",
    "files = reader.read()\n",
    "parsed_docs = [doc.parse() for doc in files]\n",
    "chunked_docs = chunk_documents(parsed_docs, size=3000, step=1500)\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"title\", \"description\", \"content\"],\n",
    "    keyword_fields=[\"filename\"]\n",
    ")\n",
    "index.fit(chunked_docs)\n",
    "\n",
    "instructions = \"\"\"\n",
    "You're a documentation assistant. Answer the QUESTION based on the CONTEXT.\n",
    "\n",
    "Use only facts from the CONTEXT when answering.\n",
    "If the answer isn't in the CONTEXT, say so.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    context = json.dumps(search_results, indent=2)\n",
    "    return prompt_template.format(\n",
    "        question=question,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "def search(query):\n",
    "    return index.search(query=query, num_results=5)\n",
    "\n",
    "def llm_structured(user_prompt, instructions, output_format):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=messages,\n",
    "        text_format=output_format\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n",
    "print(f\"Indexed {len(chunked_docs)} chunks from {len(files)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4906d25-10bb-4def-b47c-06c5f3636bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    answer: str = Field(description=\"The main answer to the user's question\")\n",
    "    found_answer: bool = Field(description=\"True if relevant information was found\")\n",
    "    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n",
    "    answer_type: Literal[\"how-to\", \"explanation\", \"troubleshooting\", \"comparison\", \"reference\"] = Field(description=\"Category of the answer\")\n",
    "    followup_questions: list[str] = Field(description=\"Suggested follow-up questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703f6de2-e674-4880-93b8-9894f069582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, output_format=RAGResponse):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    return llm_structured(prompt, instructions, output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ffaccb-4a01-46b4-ae9a-ee62d938be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found_answer: True\n",
      "confidence: 0.95\n",
      "answer_type: explanation\n",
      "answer: Using an LLM as a judge involves evaluating text responses based on custom criteria. There are two m...\n"
     ]
    }
   ],
   "source": [
    "query = 'llm as a judge'\n",
    "\n",
    "answer = rag(query)\n",
    "\n",
    "print(f\"found_answer: {answer.found_answer}\")\n",
    "print(f\"confidence: {answer.confidence}\")\n",
    "print(f\"answer_type: {answer.answer_type}\")\n",
    "print(f\"answer: {answer.answer[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07754b7-cfb8-45a4-b9c3-2fa401448f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c45699f-7301-46ce-9ed1-3efcc3ab4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m155 packages\u001b[0m \u001b[2min 3.74s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m16 packages\u001b[0m \u001b[2min 28.45s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2026.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2026.1.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==5.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354c8aec-c5e1-40ab-b40f-b91dd7f4edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34108b8-5d29-4135-836f-4f31b82ac84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a62f54d23942cc880b9c955008b739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9bc766-ddbe-4ee3-ae6c-0bce930d7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'install Evidently locally' # -\n",
    "q2 = 'how can I set up evidently in my projects?' # -> [1000+]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e5eaac-ff3a-4095-8a25-0628260b76c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07184873, -0.02879701,  0.0612349 , -0.0181076 ,  0.12533106,\n",
       "       -0.04134636, -0.06354983, -0.08986848, -0.04142817, -0.0446535 ,\n",
       "        0.06421643,  0.02077088,  0.00219164,  0.00508833, -0.00833959,\n",
       "       -0.03770021,  0.03059419, -0.0484462 ,  0.06848747, -0.01030121],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model.encode(q1)\n",
    "v1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ffd2f54-f80b-472f-8c5d-cbec9c4fcdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1655cade-c92e-4f46-9959-75174bb3b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = model.encode(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11f97db4-334e-4252-b111-f6879f77e848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.43477958)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b92589f-8cfa-41f9-b655-65e0459cc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = 'how do i bake pretzels?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ed32332-2172-4828-bd49-a24140d926da",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = model.encode(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8647d469-13bd-47d2-b4b1-a6e7ff4bf67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.022272678)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.dot(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da5a4552-51d5-4a1c-8481-351b65b6292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in chunked_docs:\n",
    "    title = doc.get('title', '')\n",
    "    description = doc.get('description', '')\n",
    "    content = doc.get('content', '')\n",
    "\n",
    "    text = title + \" \" + description + \" \" + content\n",
    "    texts.append(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfe52a44-a25a-4ce0-905a-1f88d5df40a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72ce2dd06e6481cb6fac61852bb874d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9435fd8a-333e-447d-a702-11c7d73caeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 384)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "540a0b2a-39e4-4d16-b884-ce3a95989e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04849773,  0.06601194,  0.01094063, ...,  0.03090537,\n",
       "         0.06879068,  0.05070846],\n",
       "       [-0.0323205 , -0.01947777, -0.01677329, ...,  0.01519906,\n",
       "         0.0237962 , -0.00774648],\n",
       "       [-0.02108493, -0.05657953,  0.00483409, ..., -0.04806887,\n",
       "         0.07104319,  0.04317407],\n",
       "       ...,\n",
       "       [-0.00160594, -0.04139439, -0.05660466, ...,  0.05727464,\n",
       "         0.0903789 , -0.0273216 ],\n",
       "       [-0.02243875, -0.0011336 , -0.05355769, ...,  0.04080837,\n",
       "         0.0889126 , -0.00143775],\n",
       "       [-0.06048306, -0.05174244,  0.01422591, ...,  0.00431385,\n",
       "         0.09889203,  0.00393771]], shape=(385, 384), dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95d961ae-aba9-45c7-8448-4041049804b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0795968 ,  0.12935531,  0.18664983,  0.260543  ,  0.08233505,\n",
       "       -0.02807797, -0.07214396, -0.05210198, -0.01589224,  0.00971274,\n",
       "       -0.0527408 , -0.10643847,  0.04062283,  0.0634449 , -0.04217617],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = embeddings.dot(v1)\n",
    "scores[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fd57c8d-4360-455e-87cd-c06280f86dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cc25ad5-331d-4a1c-80db-29e786fa0f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x1f3f7e7e7b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields=['filename'])\n",
    "vindex.fit(embeddings, chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "087de64c-f24c-4f1d-a36a-5b0dcd668291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, num_results=5):\n",
    "    vector = model.encode(query)\n",
    "    return vindex.search(vector, num_results=num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d31c933-9c35-4b6d-bfaf-73a5e15a0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_vector(query, output_format=RAGResponse):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    return llm_structured(prompt, instructions, output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e13378c8-6762-4a87-88f2-93c1eddc6421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: llm as a judge\n",
      "found_answer: True\n",
      "confidence: 0.95\n",
      "answer: Using an LLM as a judge involves evaluating text responses against custom criteria or comparing them to reference responses. The primary applications include:\n",
      "\n",
      "1. **Reference-based Evaluation**: This ...\n"
     ]
    }
   ],
   "source": [
    "answer = rag_vector(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"found_answer: {answer.found_answer}\")\n",
    "print(f\"confidence: {answer.confidence}\")\n",
    "print(f\"answer: {answer.answer[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78743f7c-a4df-46f3-807f-b75b85e0f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query):\n",
    "    vector_results = vector_search(query)\n",
    "    text_results = search(query)\n",
    "    return vector_results + text_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af832f0c-985b-4b45-9cd6-686ebf975222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = hybrid_search(query)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e95d5e-7d13-4c32-b3be-6a7624bd8b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
