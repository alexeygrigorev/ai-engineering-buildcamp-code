{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43385a9e-01f4-40e1-9199-6c2f78ca5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a983e6ea-c290-44c7-bb00-b2dd03a95b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b33619c-051d-4106-a17c-77db864630e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "  'date': {'title': 'Date', 'type': 'string'},\n",
       "  'participants': {'items': {'type': 'string'},\n",
       "   'title': 'Participants',\n",
       "   'type': 'array'}},\n",
       " 'required': ['name', 'date', 'participants'],\n",
       " 'title': 'CalendarEvent',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalendarEvent.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe4ff96-5007-4a11-8b42-e224f107f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=CalendarEvent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb384cd7-5361-4c1c-9947-af6141add746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad00947d-fc8b-48a5-8147-a3299870a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91aa7081-f05a-4345-8dcb-da20f61b2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe6b9ada-6d1b-49d1-922f-7c24e70ee4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "537d4c18-fa73-41b3-8601-fc49751be47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=CalendarEvent\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7595f966-3a84-447d-8bb1-407849c9decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: Science Fair  \n",
      "Participants: Alice and Bob  \n",
      "Day: Friday\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69580327-78c2-4990-83c7-940e72b8a745",
   "metadata": {},
   "source": [
    "Event Information:\n",
    "- Event: Science Fair\n",
    "- Participants: Alice and Bob\n",
    "- Day: Friday\n",
    "\n",
    "\n",
    "Event: Science Fair  \n",
    "Participants: Alice and Bob  \n",
    "Day: Friday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d173c-9d0c-4874-859b-26a14f9e350b",
   "metadata": {},
   "source": [
    "## Structured RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0291b569-85d8-4eb7-9c06-230965bdf4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gitsource import GithubRepositoryDataReader, chunk_documents\n",
    "from minsearch import Index\n",
    "\n",
    "reader = GithubRepositoryDataReader(\n",
    "    repo_owner=\"evidentlyai\",\n",
    "    repo_name=\"docs\",\n",
    "    allowed_extensions={\"md\", \"mdx\"},\n",
    ")\n",
    "files = reader.read()\n",
    "\n",
    "parsed_docs = [doc.parse() for doc in files]\n",
    "chunked_docs = chunk_documents(parsed_docs, size=3000, step=1500)\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"title\", \"description\", \"content\"],\n",
    "    keyword_fields=[\"filename\"]\n",
    ")\n",
    "index.fit(chunked_docs)\n",
    "\n",
    "print(f\"Indexed {len(chunked_docs)} chunks from {len(files)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f50ea4-2f42-494a-a084-5acd6cd536ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        num_results=5\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2620bcb-7556-459e-99d3-6e645e511cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "instructions = \"\"\"\n",
    "You're a documentation assistant. Answer the QUESTION based on the CONTEXT from our documentation.\n",
    "\n",
    "Use only facts from the CONTEXT when answering.\n",
    "If the answer isn't in the CONTEXT, say so.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    context = json.dumps(search_results, indent=2)\n",
    "    return prompt_template.format(\n",
    "        question=question,\n",
    "        context=context\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1644e0f6-ab39-412d-bc33-e19d6d010bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt, instructions=None, model=\"gpt-4o-mini\"):\n",
    "    messages = []\n",
    "\n",
    "    if instructions:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instructions\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    })\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d14426-6663-4725-b9c9-1f266c75eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    return llm(prompt, instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4711ff1-cb47-4f82-8ddf-550786fe8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag('how do I implement LLM as a Judge?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa3670b6-cba2-4776-9328-8137c18970b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_structured(\n",
    "        user_prompt,\n",
    "        output_type,\n",
    "        instructions=None,\n",
    "        model=\"gpt-4o-mini\",\n",
    "    ):\n",
    "    messages = []\n",
    "\n",
    "    if instructions:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instructions\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    })\n",
    "\n",
    "    response = openai_client.responses.parse(\n",
    "        model=model,\n",
    "        input=messages,\n",
    "        text_format=output_type\n",
    "    )\n",
    "\n",
    "    return response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1487b517-b636-423e-ba63-82bb40829c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_structured(\n",
    "    instructions=\"Extract the event information.\",\n",
    "    user_prompt=\"Alice and Bob are going to a science fair on Friday.\",\n",
    "    output_type=CalendarEvent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40298c18-e638-4922-ad6b-dbf47ccc1b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb8a9505-7cfb-4278-9299-f9ade1ca19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGResponse(BaseModel):\n",
    "    answer: str\n",
    "    found_answer: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98ff274d-addd-4d33-bb03-20f926b2f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_structured(query, output_type=RAGResponse):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    return llm_structured(\n",
    "        instructions=instructions,\n",
    "        user_prompt=prompt,\n",
    "        output_type=output_type,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb20e847-4c30-447e-bc77-6d7a98a429e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To perform LLM evaluations, you can follow these steps:\n",
      "\n",
      "1. **Install the Required Package**: Instal\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do i do llm evals?')\n",
    "\n",
    "print(answer.answer[:100])\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e075b63-11fa-498f-ba30-cfe07f5c4c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not contain any information about installing Kafka on Windows.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?')\n",
    "\n",
    "print(answer.answer[:100])\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "509b2d23-8075-48aa-b3c4-cd555679fe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'answer': {'title': 'Answer', 'type': 'string'},\n",
       "  'found_answer': {'title': 'Found Answer', 'type': 'boolean'}},\n",
       " 'required': ['answer', 'found_answer'],\n",
       " 'title': 'RAGResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAGResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "731187be-7d26-42a5-b5ab-e54e4431149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    answer: Optional[str] = None\n",
    "    found_answer: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "955c6311-3b62-434a-aa6b-ccd3931ccbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'answer': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Answer'},\n",
       "  'found_answer': {'title': 'Found Answer', 'type': 'boolean'}},\n",
       " 'required': ['found_answer'],\n",
       " 'title': 'RAGResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAGResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24198a98-5759-4387-8b7a-df8e89f6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not contain information on how to install Kafka on Windows.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n",
    "\n",
    "print(answer.answer)\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "135ff272-4874-4ccc-99d4-cf1768337e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n",
    "\n",
    "print(answer.answer)\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c6cbb19-5cc5-4ae6-8d16-e24a04a9c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions = \"\"\"\n",
    "You're a documentation assistant. Answer the QUESTION based on the CONTEXT from our documentation.\n",
    "\n",
    "Use only facts from the CONTEXT when answering.\n",
    "If the answer isn't in the CONTEXT, say so.\n",
    "\n",
    "If you don't find the answer, set `answer` to None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c81047c2-eede-4bbd-a839-0a567190d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n",
    "\n",
    "print(answer.answer)\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c2ff46c-595e-483a-ae30-165de5a84bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions = \"\"\"\n",
    "You're a documentation assistant. Answer the QUESTION based on the CONTEXT from our documentation.\n",
    "\n",
    "Use only facts from the CONTEXT when answering.\n",
    "If the answer isn't in the CONTEXT, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc612983-df8d-49cf-9d26-fc0f61cd59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    The response from the documentation RAG system\n",
    "\n",
    "    If the answer to the question wasn't found in the database, `answer` is None\n",
    "    \"\"\"\n",
    "    answer: Optional[str] = None\n",
    "    found_answer: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc584e82-8984-47ab-bf43-62306eb983bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"The response from the documentation RAG system\\n\\nIf the answer to the question wasn't found in the database, `answer` is None\",\n",
       " 'properties': {'answer': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Answer'},\n",
       "  'found_answer': {'title': 'Found Answer', 'type': 'boolean'}},\n",
       " 'required': ['found_answer'],\n",
       " 'title': 'RAGResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAGResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52b86068-da0a-4684-a623-e279c4322d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n",
    "\n",
    "print(answer.answer)\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fad3a3ab-a67d-4f25-aa08-7ef85058abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    The response from the documentation RAG system\n",
    "    \"\"\"\n",
    "    answer: Optional[str] = Field(None, description=\"Answer to the question or None if it's not found\")\n",
    "    found_answer: bool = Field(description=\"True if the answer is found, False otherwise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a85b65c9-43b5-4d71-b680-919792ac785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'The response from the documentation RAG system',\n",
       " 'properties': {'answer': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': \"Answer to the question or None if it's not found\",\n",
       "   'title': 'Answer'},\n",
       "  'found_answer': {'description': 'True if the answer is found, False otherwise',\n",
       "   'title': 'Found Answer',\n",
       "   'type': 'boolean'}},\n",
       " 'required': ['found_answer'],\n",
       " 'title': 'RAGResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAGResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21ad6e5c-69b8-4e79-82a0-488c725a8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n",
    "\n",
    "print(answer.answer)\n",
    "print(answer.found_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eaa7718f-1896-491d-9f82-431e9c8d9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    This model provides a structured answer with metadata about the response,\n",
    "    including confidence, categorization, and follow-up suggestions.\n",
    "    \"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"The main answer to the user's question in markdown\")\n",
    "    found_answer: bool = Field(description=\"True if relevant information was found in the documentation\")\n",
    "    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0 indicating how certain the answer is\")\n",
    "    confidence_explanation: str = Field(description=\"Explanation about the confidence level\")\n",
    "    answer_type: Literal[\"how-to\", \"explanation\", \"troubleshooting\", \"comparison\", \"reference\"] = Field(description=\"The category of the answer\")\n",
    "    followup_questions: list[str] = Field(description=\"Suggested follow-up questions the user might want to ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e71bc72-0fb0-411d-b8df-add7652c8eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'This model provides a structured answer with metadata about the response,\\nincluding confidence, categorization, and follow-up suggestions.',\n",
       " 'properties': {'answer': {'description': \"The main answer to the user's question in markdown\",\n",
       "   'title': 'Answer',\n",
       "   'type': 'string'},\n",
       "  'found_answer': {'description': 'True if relevant information was found in the documentation',\n",
       "   'title': 'Found Answer',\n",
       "   'type': 'boolean'},\n",
       "  'confidence': {'description': 'Confidence score from 0.0 to 1.0 indicating how certain the answer is',\n",
       "   'title': 'Confidence',\n",
       "   'type': 'number'},\n",
       "  'confidence_explanation': {'description': 'Explanation about the confidence level',\n",
       "   'title': 'Confidence Explanation',\n",
       "   'type': 'string'},\n",
       "  'answer_type': {'description': 'The category of the answer',\n",
       "   'enum': ['how-to',\n",
       "    'explanation',\n",
       "    'troubleshooting',\n",
       "    'comparison',\n",
       "    'reference'],\n",
       "   'title': 'Answer Type',\n",
       "   'type': 'string'},\n",
       "  'followup_questions': {'description': 'Suggested follow-up questions the user might want to ask',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Followup Questions',\n",
       "   'type': 'array'}},\n",
       " 'required': ['answer',\n",
       "  'found_answer',\n",
       "  'confidence',\n",
       "  'confidence_explanation',\n",
       "  'answer_type',\n",
       "  'followup_questions'],\n",
       " 'title': 'RAGResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAGResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6fcc64c4-8ec5-4756-bbe6-a311d0f46b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_structured('how do I evaluate llms', RAGResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0022ec1c-357f-4e67-b1be-b840bc15117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### How to Evaluate LLMs\n",
      "\n",
      "1. **Setup**: Start by installing the `evidently` package:\n",
      "   ```bash\n",
      "   p\n",
      "0.95\n",
      "The steps provided are directly derived from the context and outline a clear pathway to evaluating LLMs using multiple judges.\n",
      "how-to\n",
      "['What are the best practices for evaluating LLM outputs?', 'How do I troubleshoot issues with LLM evaluations?', 'Can I use custom metrics for LLM evaluation?']\n"
     ]
    }
   ],
   "source": [
    "print(answer.answer[:100])\n",
    "print(answer.confidence)\n",
    "print(answer.confidence_explanation)\n",
    "print(answer.answer_type)\n",
    "print(answer.followup_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "260bd06a-282b-4445-aee8-68dabd17f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', RAGResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "540a00e7-bff9-47e2-922e-f7f4d63a9e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided documentation does not contain any information on installing Kafka on Windows. Please r\n",
      "0.0\n",
      "The relevant information for installing Kafka on Windows is not mentioned in the provided context.\n",
      "reference\n",
      "['Where can I find the official Kafka installation guide?', 'What are the system requirements for Kafka on Windows?', 'Can you provide troubleshooting tips for installing Kafka?']\n"
     ]
    }
   ],
   "source": [
    "print(answer.answer[:100])\n",
    "print(answer.confidence)\n",
    "print(answer.confidence_explanation)\n",
    "print(answer.answer_type)\n",
    "print(answer.followup_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9576ea8-3224-43c4-b0c9-a77cda6c655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import model_validator\n",
    "\n",
    "\n",
    "class AnswerNotFound(BaseModel):\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "class AnswerResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    If answer is found, 'answer' is populated.\n",
    "    If no answer is found, 'answer_not_found' is populated.\n",
    "    Only one of the two fields can be set at a time. Never both or neither.\n",
    "    \"\"\"\n",
    "\n",
    "    answer_not_found: Optional[AnswerNotFound] = None\n",
    "    found_answer: bool\n",
    "    answer: Optional[RAGResponse] = None\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def check_consistency(self):\n",
    "        if self.answer is not None and self.answer_not_found is not None:\n",
    "            raise ValueError(\"Provide either 'answer' or 'answer_not_found', not both.\")\n",
    "\n",
    "        if self.answer is None and self.answer_not_found is None:\n",
    "            raise ValueError(\"Provide either 'answer' or 'answer_not_found'.\")\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ecd854c0-f45f-40a8-93dc-59c315afa1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AnswerNotFound': {'properties': {'explanation': {'title': 'Explanation',\n",
       "     'type': 'string'}},\n",
       "   'required': ['explanation'],\n",
       "   'title': 'AnswerNotFound',\n",
       "   'type': 'object'},\n",
       "  'RAGResponse': {'description': 'This model provides a structured answer with metadata about the response,\\nincluding confidence, categorization, and follow-up suggestions.',\n",
       "   'properties': {'answer': {'description': \"The main answer to the user's question in markdown\",\n",
       "     'title': 'Answer',\n",
       "     'type': 'string'},\n",
       "    'found_answer': {'description': 'True if relevant information was found in the documentation',\n",
       "     'title': 'Found Answer',\n",
       "     'type': 'boolean'},\n",
       "    'confidence': {'description': 'Confidence score from 0.0 to 1.0 indicating how certain the answer is',\n",
       "     'title': 'Confidence',\n",
       "     'type': 'number'},\n",
       "    'confidence_explanation': {'description': 'Explanation about the confidence level',\n",
       "     'title': 'Confidence Explanation',\n",
       "     'type': 'string'},\n",
       "    'answer_type': {'description': 'The category of the answer',\n",
       "     'enum': ['how-to',\n",
       "      'explanation',\n",
       "      'troubleshooting',\n",
       "      'comparison',\n",
       "      'reference'],\n",
       "     'title': 'Answer Type',\n",
       "     'type': 'string'},\n",
       "    'followup_questions': {'description': 'Suggested follow-up questions the user might want to ask',\n",
       "     'items': {'type': 'string'},\n",
       "     'title': 'Followup Questions',\n",
       "     'type': 'array'}},\n",
       "   'required': ['answer',\n",
       "    'found_answer',\n",
       "    'confidence',\n",
       "    'confidence_explanation',\n",
       "    'answer_type',\n",
       "    'followup_questions'],\n",
       "   'title': 'RAGResponse',\n",
       "   'type': 'object'}},\n",
       " 'description': \"If answer is found, 'answer' is populated.\\nIf no answer is found, 'answer_not_found' is populated.\\nOnly one of the two fields can be set at a time. Never both or neither.\",\n",
       " 'properties': {'answer_not_found': {'anyOf': [{'$ref': '#/$defs/AnswerNotFound'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None},\n",
       "  'found_answer': {'title': 'Found Answer', 'type': 'boolean'},\n",
       "  'answer': {'anyOf': [{'$ref': '#/$defs/RAGResponse'}, {'type': 'null'}],\n",
       "   'default': None}},\n",
       " 'required': ['found_answer'],\n",
       " 'title': 'AnswerResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnswerResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3e660376-5686-461f-a45d-0a43b5937ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerResponse(answer_not_found=AnswerNotFound(explanation='The context provided does not include any information about installing Kafka on Windows.'), found_answer=False, answer=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = rag_structured('how do I install kafka on windows?', AnswerResponse)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45278af2-05bb-4481-884b-6e106c0b80ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerResponse(answer_not_found=None, found_answer=True, answer=RAGResponse(answer='To run LLM evaluations, follow these steps:\\n\\n1. **Connect to Evidently Cloud**: Ensure you are connected and have created a project.\\n   ```python\\n   ws = CloudWorkspace(token=\"YOUR_API_TOKEN\", url=\"https://app.evidently.cloud\")\\n   project = ws.create_project(\"Your Project Name\", org_id=\"YOUR_ORG_ID\")\\n   project.save()\\n   ```\\n\\n2. **Prepare Your Dataset**: Create a dataset with computed descriptors (like text length, sentence count). For example:\\n   ```python\\n   data = [\\n       [\"Question 1\", \"Response 1\"],\\n       [\"Question 2\", \"Response 2\"]\\n   ]\\n   ref_data = pd.DataFrame(data, columns=[\"question\", \"target_response\"])\\n   ref_dataset = Dataset.from_pandas(ref_data,\\n       data_definition=DataDefinition(),\\n       descriptors=[\\n           TextLength(\"target_response\", alias=\"Length\"),\\n           SentenceCount(\"target_response\", alias=\"Sentence\")\\n       ])\\n   ```\\n\\n3. **Run an Evaluation Report**: Create and run a Report using the `TextEvals()` preset:\\n   ```python\\n   report = Report([\\n       TextEvals(),\\n   ])\\n   my_eval = report.run(ref_dataset, None)\\n   ```\\n\\n4. **Explore the Results**: Check the evaluation results in the Explore view within your project.\\n\\n5. **Optional Steps**: You can set up dashboards to track results over time and configure alerts based on test conditions. \\n   - For further customization and analysis, you can modify the report composition or add tests as needed.\\n\\nRefer to the detailed documentation for more information on descriptors and customization options.', found_answer=True, confidence=0.9, confidence_explanation='The response synthesizes steps from the documentation provided on running LLM evaluations and includes essential code snippets and explanations.', answer_type='how-to', followup_questions=['What are descriptors in LLM evaluations?', 'How can I customize my evaluation report?', 'What is the Explore view in Evidently?']))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = rag_structured('how do I run llm evals?', AnswerResponse)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0a17754-f0d1-4444-9f46-a7f29eaa8f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error:\n",
      "1 validation error for AnswerResponse\n",
      "found_answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "try:\n",
    "    AnswerResponse()\n",
    "except ValidationError as e:\n",
    "    print(\"Validation error:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0c333-8d7e-41bf-b3aa-23e781ccc616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
