{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6210384e-5a19-4af4-b997-a4087569db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "zai_client = OpenAI(\n",
    "    api_key=os.getenv(\"ZAI_API_KEY\"),\n",
    "    base_url=\"https://api.z.ai/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26601ccf-b9e9-482c-95e4-010aeefcb5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
    "]\n",
    "\n",
    "response = zai_client.chat.completions.create(\n",
    "    model='glm-4.7',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb81ac64-b894-4ab8-a3fc-07fd4b28da44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bell above the door chimed, shattering the heavy silence of the shop. Elias didn’t look up immediately. His eyes were magnified by thick lenses, focused intensely on the mainspring of a 19th-century pocket watch.\n",
      "\n",
      "\"Excuse me? Can you fix this?\"\n",
      "\n",
      "The voice was soft, young. Elias lowered his loupe. Standing before the counter was a girl, no older than twenty, clutching a silver wristwatch with a cracked face.\n",
      "\n",
      "\"It stopped when he passed,\" she whispered, placing it gently on the velvet mat. \"My grandfather. It meant the world to him.\"\n",
      "\n",
      "Elias picked it up. The metal was cold. He turned it over to inspect the case back. His breath hitched. The engraving was faint but legible: *To E, My heart, M.*\n",
      "\n",
      "Elias hadn’t been called 'E' in forty years. He remembered giving this watch to Michael, his best friend, the night before Michael left for the war. He remembered Michael never returning, and the letter that arrived later saying Michael had met someone overseas.\n",
      "\n",
      "\"I can fix it,\" Elias said, his voice gruffer than he intended.\n",
      "\n",
      "He worked through the night. The gears were seized, rusted by time and neglect, much like his own memories. But by dawn, the balance wheel was oscillating perfectly. The heartbeat of a lost era resumed.\n",
      "\n",
      "When the girl returned, Elias handed it to her. The silver band glinted under the shop lights.\n",
      "\n",
      "\"It’s running again,\" he said.\n",
      "\n",
      "She smiled, tears in her eyes. \"Thank you.\"\n",
      "\n",
      "He watched her leave, the bell chiming once more. He didn't tell her about the engraving. He just listened as the ticking of the clocks on the wall drowned out the silence of his regret."
     ]
    }
   ],
   "source": [
    "story_prompt = [{\"role\": \"user\", \"content\": \"Tell me a very short story (250 words)\"}]\n",
    "\n",
    "response = zai_client.chat.completions.create(\n",
    "    model='glm-4.7',\n",
    "    messages=story_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ddd175-045d-44e6-9054-770b2f6b9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef85736-6517-4cf9-82b7-619d60b34611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the event information extracted from the sentence:\n",
      "\n",
      "*   **Event:** Science Fair\n",
      "*   **Attendees:** Alice and Bob\n",
      "*   **Date:** Friday\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "]\n",
    "\n",
    "response = zai_client.chat.completions.create(\n",
    "    model='glm-4.7',\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": CalendarEvent.model_json_schema()\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44652bf1-ad3f-4c0a-ab9c-d16ada20550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "zai_anthropic_client = Anthropic(\n",
    "    api_key=os.getenv(\"ZAI_API_KEY\"),\n",
    "    base_url=\"https://api.z.ai/api/anthropic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a85c708-6da1-4358-a8c2-3b701c8e8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is **4**.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n",
    "\n",
    "response = zai_anthropic_client.messages.create(\n",
    "    model=\"glm-4.7\",\n",
    "    max_tokens=100,\n",
    "    messages=messages\n",
    ")\n",
    "print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a32bbe4-d092-4b32-9a3d-1c0af89dc1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 2 + 2 is 4. \n",
      "\n",
      "Here's the step-by-step breakdown:\n",
      "1. Start with the number 2.\n",
      "2. Add another 2 to it.\n",
      "3. The total is 4.\n",
      "\n",
      "Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "response = zai_anthropic_client.messages.create(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    max_tokens=100,\n",
    "    messages=messages\n",
    ")\n",
    "print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86691b44-278e-4f57-9027-98c3f0de48e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glm-4.7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f017cc0-a69b-48f5-b6f2-49cde022c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_output_tool = {\n",
    "    \"name\": \"final_result\",\n",
    "    \"description\": \"Tool for structured output\",\n",
    "    \"input_schema\": CalendarEvent.model_json_schema()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "441bad25-3778-4c1a-8464-d346c9aebde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Extract the event information.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "]\n",
    "\n",
    "response = zai_anthropic_client.messages.create(\n",
    "    model=\"glm-4.7\",\n",
    "    max_tokens=1024,\n",
    "    system=instructions,\n",
    "    messages=messages,\n",
    "    tools=[structured_output_tool],\n",
    "    tool_choice={\"type\": \"tool\", \"name\": structured_output_tool['name']}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8d1c03c-ab97-4974-a58b-0651e45436ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolUseBlock(id='call_79e7e4611cd9400da4556937', input={'name': 'Science Fair', 'date': 'Friday', 'participants': ['Alice', 'Bob']}, name='final_result', type='tool_use')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "330087b3-aa25-4438-bdbc-fe9dd81ee4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "event = CalendarEvent.model_validate(response.content[0].input)\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba9764de-ebca-4471-a892-3d498fe23da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "import rag\n",
    "index = rag.initialize_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67848aa3-9348-490a-b412-1e31a345a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZaiRAG(rag.RAG):\n",
    "\n",
    "    def llm(self, user_prompt):\n",
    "        structured_output_tool = {\n",
    "            \"name\": \"final_result\",\n",
    "            \"description\": \"Tool for structured output\",\n",
    "            \"input_schema\": self.output_type.model_json_schema()\n",
    "        }\n",
    "        \n",
    "        messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "        \n",
    "        response = self.llm_client.messages.create(\n",
    "            model=self.model_name,\n",
    "            max_tokens=1024,\n",
    "            system=self.rag_instructions,\n",
    "            messages=messages,\n",
    "            tools=[structured_output_tool],\n",
    "            tool_choice={\"type\": \"tool\", \"name\": structured_output_tool['name']}\n",
    "        )\n",
    "        \n",
    "        output = self.output_type.model_validate(response.content[0].input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9890f77b-f0aa-4d4c-85cf-bc0719a72977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LLM as a Judge\n",
      "\n",
      "LLM as a judge is an evaluation ...\n"
     ]
    }
   ],
   "source": [
    "zai_rag = ZaiRAG(\n",
    "    index,\n",
    "    zai_anthropic_client,\n",
    "    model_name='glm-4.7'\n",
    ")\n",
    "\n",
    "response = zai_rag.rag('llm as a judge')\n",
    "print(response.answer[:50] + '...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56249b50-f0d0-418a-af8b-d3fbb1986904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
