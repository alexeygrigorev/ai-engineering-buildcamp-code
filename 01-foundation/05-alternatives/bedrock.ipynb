{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b407a7d7-5153-4f0a-8b25-3f65a757ca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m165 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m143 packages\u001b[0m \u001b[2min 0.15ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3560f35b-e5eb-4171-93a9-a8b26a2cf2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5c4639-6b2b-40ce-81da-0ae021c7b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eu-west-1' # \"us-east-1\"\n",
    "\n",
    "bedrock_boto_client = boto3.client(\"bedrock-runtime\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33582a97-0df1-4fc9-b41c-d2a841d18495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"minimax.minimax-m2\"\n",
    "model_id = \"openai.gpt-oss-120b-1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "535eb64a-669e-4938-85a6-a8fe7fbdabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 512,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b913264-8bb2-4afc-9096-cb8e4e6ae1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': '<reasoning>The user asks: \"Describe the purpose of a \\'hello world\\' program in one line.\" So we need to give a one-line description. Provide concise answer.\\n\\nProbably: \"A \\'Hello, World!\\' program demonstrates the basic syntax and verifies that a language\\'s toolchain successfully compiles and runs code.\" Something like that. One line.\\n\\nI\\'ll output a single sentence.\\n\\n</reasoning>A ‚ÄúHello, World!‚Äù program simply verifies that a language‚Äôs compiler/interpreter and runtime are correctly set up by printing a basic output.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1769767687,\n",
       " 'id': 'chatcmpl-33510a6a-0aa6-4b75-a8cb-122d142929f0',\n",
       " 'model': 'openai.gpt-oss-120b-1:0',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': 'default',\n",
       " 'usage': {'completion_tokens': 113, 'prompt_tokens': 79, 'total_tokens': 192}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = bedrock_boto_client.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1418d7a3-abd6-4bc1-be73-38ba187cb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<reasoning>The user asks: \"Describe the purpose of a 'hello world' program in one line.\" So we need to give a one-line description. Provide concise answer.\n",
      "\n",
      "Probably: \"A 'Hello, World!' program demonstrates the basic syntax and verifies that a language's toolchain successfully compiles and runs code.\" Something like that. One line.\n",
      "\n",
      "I'll output a single sentence.\n",
      "\n",
      "</reasoning>A ‚ÄúHello, World!‚Äù program simply verifies that a language‚Äôs compiler/interpreter and runtime are correctly set up by printing a basic output.\n"
     ]
    }
   ],
   "source": [
    "output_text = model_response['choices'][0]['message']['content']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96d32691-5a53-4f7f-9024-e6b0991984a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75600ede-d457-44aa-aa3c-19918789980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"The purpose of a 'hello world' program is to provide a simple introduction to a programming language, demonstrating its basic syntax and confirming that the environment is set up correctly.\"},\n",
       "   'stop_reason': 'stop'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'mistral.mistral-large-2402-v1:0'\n",
    "\n",
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# also works\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": user_prompt}\n",
    "# ]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":[{\"text\": user_prompt}]}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 512,\n",
    "})\n",
    "\n",
    "response = bedrock_boto_client.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a06bba8-4f46-4e67-90e4-7643024f9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of a 'hello world' program is to provide a simple introduction to a programming language, demonstrating its basic syntax and confirming that the environment is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "output_text = model_response['choices'][0]['message']['content']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d198d3e-5e2b-431c-b0b7-27e26f047cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e639dbe2-f073-4c98-9119-9abfaa46d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'message': {'content': [{'text': \"A 'hello world' program serves as a simple introductory example to demonstrate the basic syntax and execution flow of a programming language.\"}],\n",
       "   'role': 'assistant'}},\n",
       " 'stopReason': 'end_turn',\n",
       " 'usage': {'inputTokens': 60,\n",
       "  'outputTokens': 28,\n",
       "  'totalTokens': 88,\n",
       "  'cacheReadInputTokenCount': 0,\n",
       "  'cacheWriteInputTokenCount': 0}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'global.amazon.nova-2-lite-v1:0'\n",
    "\n",
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":[{\"text\": user_prompt}]}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "})\n",
    "\n",
    "response = bedrock_boto_client.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44047ea0-eb37-4244-8d82-06a8425aa6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'hello world' program serves as a simple introductory example to demonstrate the basic syntax and execution flow of a programming language.\n"
     ]
    }
   ],
   "source": [
    "output_text = model_response['output']['message']['content'][0]['text']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd45cbd-13a4-40b0-9b6b-a2b19b5c4279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5d7841f-dc02-47d7-b7b7-f3cf790faf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'claude-sonnet-4-5-20250929',\n",
       " 'id': 'msg_bdrk_017gYXDQa1Gho8ZrnUaHpnnd',\n",
       " 'type': 'message',\n",
       " 'role': 'assistant',\n",
       " 'content': [{'type': 'text',\n",
       "   'text': \"A 'Hello World' program demonstrates the basic syntax of a programming language and verifies that the development environment is properly configured.\"}],\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'usage': {'input_tokens': 23,\n",
       "  'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'cache_creation': {'ephemeral_5m_input_tokens': 0,\n",
       "   'ephemeral_1h_input_tokens': 0},\n",
       "  'output_tokens': 29}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'global.anthropic.claude-sonnet-4-5-20250929-v1:0'\n",
    "\n",
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":[{\"type\": \"text\", \"text\": user_prompt}]}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "})\n",
    "\n",
    "response = bedrock_boto_client.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4d8e13d-7912-435d-b5ba-1b3c58218fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'Hello World' program demonstrates the basic syntax of a programming language and verifies that the development environment is properly configured.\n"
     ]
    }
   ],
   "source": [
    "output_text = model_response['content'][0]['text']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620a0b0-8ad4-4ab8-9253-95c4057e341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7233e803-76ac-48ae-b32a-461e37f1f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'hello world' program serves as a simple introductory example to demonstrate the basic syntax and execution flow of a programming language."
     ]
    }
   ],
   "source": [
    "model_id = 'global.amazon.nova-2-lite-v1:0'\n",
    "\n",
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":[{\"text\": user_prompt}]}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "})\n",
    "\n",
    "response = bedrock_boto_client.invoke_model_with_response_stream(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "stream = response['body']\n",
    "\n",
    "for event in stream:\n",
    "    chunk = json.loads(event['chunk']['bytes'])\n",
    "    if 'contentBlockDelta' not in chunk:\n",
    "        continue\n",
    "    content_block  = chunk['contentBlockDelta']\n",
    "    if 'delta' not in content_block:\n",
    "        continue\n",
    "    print(content_block['delta']['text'], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3eb3a6ac-9b13-486e-8a1c-3b8334261ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \"Hello World\" program demonstrates the basic syntax of a programming language by displaying a simple message to confirm the development environment is working correctly."
     ]
    }
   ],
   "source": [
    "model_id = 'global.anthropic.claude-sonnet-4-5-20250929-v1:0'\n",
    "\n",
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":[{\"type\": \"text\", \"text\": user_prompt}]}\n",
    "]\n",
    "\n",
    "request = json.dumps({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "})\n",
    "\n",
    "response = bedrock_boto_client.invoke_model_with_response_stream(\n",
    "    modelId=model_id,\n",
    "    body=request\n",
    ")\n",
    "\n",
    "stream = response['body']\n",
    "\n",
    "for event in stream:\n",
    "    chunk = json.loads(event['chunk']['bytes'])\n",
    "    # print(chunk)\n",
    "\n",
    "    if 'delta' not in chunk:\n",
    "        continue\n",
    "    delta = chunk['delta']\n",
    "    if 'text' not in delta:\n",
    "        continue\n",
    "    print(delta['text'], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b1e3b-9fdb-476f-8774-76d591aac2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "882a5c39-1d22-49ce-a37f-59839d367d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06ebe1-72b0-4e78-afcd-2de6efa7f984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6e862f1-7a95-4c5c-bab7-8cb5cc794134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "base_url = f\"https://bedrock-runtime.{region}.amazonaws.com/openai/v1\"\n",
    "\n",
    "bedrock_openai_client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=os.getenv(\"AWS_BEARER_TOKEN_BEDROCK\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ecbb170-3ef7-429f-92ed-0945f06246d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"minimax.minimax-m2\"\n",
    "model_id = \"openai.gpt-oss-120b-1:0\"\n",
    "# model_id = 'mistral.mistral-large-2402-v1:0'  # not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e55e33ed-e855-48d4-bfa7-da2dc604de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "response = bedrock_openai_client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c0dbbb9d-9884-4a9c-ae08-1df19b5fe8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<reasoning>The user asks: \"Describe the purpose of a \\'hello world\\' program in one line.\" So we need a one-line description. Probably something like: \"It shows that a language\\'s compiler/interpreter works and demonstrates basic syntax.\" Provide in one line. So answer a single line.</reasoning>A ‚ÄúHello, World!‚Äù program simply verifies that a language‚Äôs toolchain is set up correctly and demonstrates the most basic syntax for outputting text.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2385f-894c-45a0-929d-3c162bad6ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "def05961-ce0e-4e24-b220-dabdced2bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AnthropicBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18e33b04-4e1c-4944-8ce1-8dbf3681ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_bedrock_client = AnthropicBedrock(\n",
    "    aws_region=region,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ab278f12-d1ba-4380-abfd-74639c044313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! üëãüòä How can I help you today? ‚ú®\n"
     ]
    }
   ],
   "source": [
    "model_id = 'global.anthropic.claude-sonnet-4-5-20250929-v1:0'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "]\n",
    "\n",
    "instructions = \"You are a helpful assistant. Reply with emojis.\"\n",
    "\n",
    "message = anthropic_bedrock_client.messages.create(\n",
    "    model=model_id,\n",
    "    max_tokens=1024,\n",
    "    system=instructions,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02def234-fe8c-4ec4-8265-0dd592293112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Sleepy Star\n",
      "\n",
      "High above, a tiny star named Luna grew drowsy. She'd been shining all night and her light began to flicker.\n",
      "\n",
      "\"Time for bed,\" whispered the Moon kindly.\n",
      "\n",
      "\"But who will light the way?\" Luna worried.\n",
      "\n",
      "\"Look,\" said the Moon.\n",
      "\n",
      "Below, the Sun was rising, painting the sky pink and gold. \n",
      "\n",
      "\"We take turns, little one. Now the Sun will watch over Earth while you rest.\"\n",
      "\n",
      "Luna yawned, her light growing soft and golden. As she drifted behind the clouds, she smiled. Tomorrow night, she'd shine brightly again.\n",
      "\n",
      "And she dreamed of dawn.\n",
      "\n",
      "*Goodnight.* ‚ú®"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a bedtime story (100 words)\"}\n",
    "]\n",
    "\n",
    "with anthropic_bedrock_client.messages.stream(\n",
    "    max_tokens=1024,\n",
    "    messages=messages,\n",
    "    model=model_id,\n",
    ") as stream:\n",
    "  for text in stream.text_stream:\n",
    "      print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "515a86b9-8d0e-4b20-91cb-00b0c8e0dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6d535ba-15a7-48f2-aa7b-7c1d3d9ab8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_output_tool = {\n",
    "    \"name\": \"final_result\",\n",
    "    \"description\": \"Tool for structured output\",\n",
    "    \"input_schema\": CalendarEvent.model_json_schema()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "305c3baa-57a5-4487-bed3-1546487030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Extract the event information.\"\n",
    "content = \"Alice and Bob are going to a science fair on Friday.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "response = anthropic_bedrock_client.messages.create(\n",
    "    model=model_id,\n",
    "    max_tokens=1024,\n",
    "    messages=messages,\n",
    "    tools=[structured_output_tool],\n",
    "    tool_choice={\"type\": \"tool\", \"name\": structured_output_tool['name']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "35fe0572-13b9-4f7b-9f4a-f106a110d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "event = CalendarEvent.model_validate(response.content[0].input)\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e7236229-39ea-45eb-bdb3-b5a154d3779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_structured(instructions, user_prompt, output_type, model_name):\n",
    "    structured_output_tool = {\n",
    "        \"name\": \"final_result\",\n",
    "        \"description\": \"Tool for structured output\",\n",
    "        \"input_schema\": output_type.model_json_schema()\n",
    "    }\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    response = anthropic_bedrock_client.messages.create(\n",
    "        model=model_name,\n",
    "        max_tokens=1024,\n",
    "        system=instructions,\n",
    "        messages=messages,\n",
    "        tools=[structured_output_tool],\n",
    "        tool_choice={\"type\": \"tool\", \"name\": structured_output_tool['name']}\n",
    "    )\n",
    "\n",
    "    raw_input = response.content[0].input\n",
    "    # print(raw_input)\n",
    "    output = output_type.model_validate(raw_input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0068ac5-f834-448f-8187-99b5bbb5a546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='science fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_structured(instructions, content, CalendarEvent, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b41a5834-0bbf-47b7-8178-6d7d13892a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "import rag\n",
    "index = rag.initialize_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "090395cd-55f3-43df-b0e4-1b6085336e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answer',\n",
       " 'found_answer',\n",
       " 'confidence',\n",
       " 'confidence_explanation',\n",
       " 'answer_type',\n",
       " 'followup_questions']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "df0d5709-62dc-41aa-9eb5-60547c872799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnthropicBedrockRAG(rag.RAG):\n",
    "\n",
    "    def llm(self, user_prompt):\n",
    "        instructions = f\"\"\"\n",
    "            {self.rag_instructions}\n",
    "\n",
    "            CRITICAL: make sure to create all these fields\n",
    "            in our output: {self.output_type.model_json_schema()['required']}\n",
    "\n",
    "            If we don't produce them, we fail our validation and we will have to \n",
    "            make another request. \n",
    "\n",
    "            for setting followup_questions, analyze the results and think of \n",
    "            what you suggest for the user to ask next\n",
    "        \"\"\"\n",
    "        \n",
    "        return llm_structured(\n",
    "            instructions,\n",
    "            user_prompt,\n",
    "            self.output_type,\n",
    "            self.model_name\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01537f4e-28a4-4163-8141-a8dd0c015e79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for RAGResponse\nconfidence_explanation\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nanswer_type\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nfollowup_questions\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[143]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m bedrock_rag = AnthropicBedrockRAG(\n\u001b[32m      2\u001b[39m     index,\n\u001b[32m      3\u001b[39m     anthropic_bedrock_client,\n\u001b[32m      4\u001b[39m     model_name=model_id\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mbedrock_rag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllm as a judge\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.answer[:\u001b[32m50\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\git\\ai-engineering-buildcamp-code\\01-foundation\\05-alternatives\\rag.py:105\u001b[39m, in \u001b[36mRAG.rag\u001b[39m\u001b[34m(self, question)\u001b[39m\n\u001b[32m    103\u001b[39m search_results = \u001b[38;5;28mself\u001b[39m.search(question)\n\u001b[32m    104\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m.build_prompt(question, search_results)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[142]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mAnthropicBedrockRAG.llm\u001b[39m\u001b[34m(self, user_prompt)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_prompt):\n\u001b[32m      4\u001b[39m     instructions = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.rag_instructions\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33m        what you suggest for the user to ask next\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm_structured\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mllm_structured\u001b[39m\u001b[34m(instructions, user_prompt, output_type, model_name)\u001b[39m\n\u001b[32m     19\u001b[39m raw_input = response.content[\u001b[32m0\u001b[39m].input\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# print(raw_input)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m output = \u001b[43moutput_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\git\\ai-engineering-buildcamp-code\\.venv\\Lib\\site-packages\\pydantic\\main.py:716\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    712\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    713\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for RAGResponse\nconfidence_explanation\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nanswer_type\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nfollowup_questions\n  Field required [type=missing, input_value={'answer': '# LLM as a Ju...rue, 'confidence': 0.95}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "bedrock_rag = AnthropicBedrockRAG(\n",
    "    index,\n",
    "    anthropic_bedrock_client,\n",
    "    model_name=model_id\n",
    ")\n",
    "\n",
    "response = bedrock_rag.rag(\"llm as a judge\")\n",
    "print(response.answer[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816103b1-37c3-4c89-956f-988f0effcc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
