{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c910ffbc-4e0d-48d8-bfd2-bf517178bde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccfa07a-16fa-402a-8bd7-3122d03e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "groq_client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3622b6cd-440a-44b3-b044-329fac8608b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hello\"}\n",
    "]\n",
    "\n",
    "response = groq_client.chat.completions.create(\n",
    "    model='openai/gpt-oss-120b',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169f0800-d618-48b5-829d-815313e1edbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing great, thanks for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = groq_client.responses.create(\n",
    "    model='openai/gpt-oss-120b',\n",
    "    input=\"hello how are you doing\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9287229e-6b64-45e6-9baa-14fe725c1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "import rag\n",
    "index = rag.initialize_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0b5161-516d-40a4-897f-5f53b427a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LLM as a judge** is a pattern for using a large ...\n"
     ]
    }
   ],
   "source": [
    "responses_rag = rag.RAG(index, groq_client, model_name='openai/gpt-oss-120b')\n",
    "response = responses_rag.rag(\"llm as a judge\")\n",
    "print(response.answer[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b4f37-88d3-421e-aba6-8eeffb87d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a223a7-c03f-4834-ba18-1e2e41a0d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatCompletionsRAG(rag.RAG):\n",
    "\n",
    "    def llm(self, user_prompt):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.rag_instructions},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        response = self.llm_client.chat.completions.parse(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            response_format=self.output_type\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813d8d98-f24e-47c9-8a69-0c930b356666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Using an LLM as a Judge\n",
      "\n",
      "The documentation prov...\n"
     ]
    }
   ],
   "source": [
    "responses_rag = ChatCompletionsRAG(index, groq_client, model_name='openai/gpt-oss-120b')\n",
    "response = responses_rag.rag(\"llm as a judge\")\n",
    "print(response.answer[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d3452-5c2b-4662-9867-2cfdba8263a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
