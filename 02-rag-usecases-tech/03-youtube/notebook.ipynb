{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d2aa4f-80f6-4628-a472-01ff6a6a3582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m172 packages\u001b[0m \u001b[2min 6.15s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 380ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myoutube-transcript-api\u001b[0m\u001b[2m==1.2.4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95ac5ea-9ff6-4585-85bc-eef75c74ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'r0gHbW_MmaQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac580707-9a31-44ba-a674-df64c2038dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74e85ff-4b6d-4b5a-b687-b3f26af164cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytt_api = YouTubeTranscriptApi()\n",
    "transcript = ytt_api.fetch(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6287226f-6c2e-4949-a54f-a74b669f19e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscriptSnippet(text='you. Thanks. See you.', start=3526.079, duration=4.52)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.snippets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847515ae-bc05-4b34-9ba8-bcd032bcfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float) -> str:\n",
    "    total_seconds = int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes:02}:{secs:02}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5319c51f-e666-4301-9f7f-9de4772d91c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58:46'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_timestamp(3526.079)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d1ac17-4702-42de-a696-e3469af8bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_lines = []\n",
    "\n",
    "for snippet in transcript.snippets:\n",
    "    ts = format_timestamp(snippet.start)\n",
    "    line = f'{ts} {snippet.text}'\n",
    "    transcript_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad08c27-b633-4eef-9745-4626ef09b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = '\\n'.join(transcript_lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b11a18f-8a58-4536-bb7f-5ee938902938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00 Hi everyone, welcome to the second\n",
      "00:02 iteration of AI engineering boot camp.\n",
      "00:05 So I renamed the course recently. It\n",
      "00:08 used to be called AI boot camp but there\n",
      "00:10 are so many boot camps and AI boot camps\n",
      "00:12 these days. So I was thinking if there's\n",
      "00:15 a way to somehow be different from these\n",
      "00:17 courses and uh maybe you know me by uh\n",
      "00:21 from courses u from free courses\n"
     ]
    }
   ],
   "source": [
    "print(subtitles[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16bb15ea-2bbe-4f27-8010-ba388d2b0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subtitles(transcript) -> str:\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(ts + ' ' + text)\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "subtitles = make_subtitles(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13edc300-e709-47a6-83d2-9e09ea6cd3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56264"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "subtitles_file = Path(f'subtitles_{video_id}.txt')\n",
    "subtitles_file.write_text(subtitles, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ad0cee-b6a0-4570-9724-c569f5b5ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "subtitles_file = Path(f'subtitles_{video_id}.txt')\n",
    "subtitles = subtitles_file.read_text(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67413a5b-6606-4f30-86f0-922cc8585d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b43d559-fb4f-4725-af1b-ab6767695ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(instructions, prompt, model='gpt-4o-mini'):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': instructions},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64e212f8-df5f-458f-8b29-be1a768bc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Summarize the following youtube transcript and create a timestamped\n",
    "list of video chaptes\n",
    "\n",
    "The goal is to use this as the description under the YouTube video.\n",
    "The output should be copy-pastable to youtube, so don't start the\n",
    "summary with \"the transcript provides...\". \n",
    "Don't start with \"Welcome...\", \"In this video,\" etc\n",
    "\n",
    "It should contain 2-3 paragraphs of text.\n",
    "\n",
    "Don't use any formatting in the response.\n",
    "\n",
    "The correct name of the course is \"AI Engineering Buildcamp\" \n",
    "\n",
    "After the description, create the chapter list in the following format\n",
    "\n",
    "<timestamp> <chapter name>\n",
    "\n",
    "Make sure chapters are at least 3-4 minutes long but not longer than\n",
    "6 minutes. The chapters should \n",
    "correspond to what's actually discussed in the video\n",
    "\n",
    "The chapter should start where the concept is introduced, and should be very\n",
    "precise - this is going to be used for youtube, and viewers will use it for\n",
    "quick navigation around the video\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee0f2681-a289-4f38-8007-dca44c9df2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = llm(\n",
    "    instructions=instructions,\n",
    "    prompt=subtitles,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b298e6c-cf12-4dfa-b0dc-b3a07799425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Engineering Buildcamp focuses on a hands-on approach to building AI systems, emphasizing the engineering mindset. Participants are encouraged to engage in practical programming while adhering to best practices. The course structure entails a mix of core and optional materials, ensuring learners can navigate content according to their pace. The instructor introduces the curriculum, highlights the platform used, and addresses how weekly sessions will be organized, including office hours for additional support.\n",
      "\n",
      "Over the coming weeks, the buildcamp will cover various topics, such as foundational concepts of large language models (LLMs), programming with APIs, implementing structured outputs, and building agents. Participants are to embark on mini projects and ultimately conceptualize their capstone projects, which will showcase their skills. Additionally, there's an emphasis on collaboration through a dedicated Slack community, where learners can share insights and ask questions throughout their learning journey.\n",
      "\n",
      "### Chapters\n",
      "00:00 Course Introduction and Objectives\n",
      "04:00 Overview of the Student Portal\n",
      "08:30 Course Structure and Curriculum\n",
      "12:50 Week 1 Overview: Course Fundamentals\n",
      "17:10 Week 2: Buffer Week and Additional Use Cases\n",
      "20:40 Week 3: Introduction to Agents\n",
      "24:20 Week 4: Testing Agents\n",
      "28:10 Week 5: Monitoring and Logs\n",
      "32:20 Week 6: Evaluation of Agents\n",
      "36:00 Weeks 7-9: Project Work and Capstone\n",
      "40:10 Live Interaction and Community Overview\n",
      "45:30 Tools and AI-Assisted Development\n",
      "49:00 Libraries and Resources Overview\n",
      "53:20 Course Wrap-Up and Q&A\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cacbba-b4c0-4ec7-882d-1d6b082b5ceb",
   "metadata": {},
   "source": [
    "<17:10> <Week 3: Agents and Interactive Learning>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308146e1-b056-4b1f-a157-a5b3215c69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Chapter(BaseModel):\n",
    "    timestamp: str\n",
    "    title: str\n",
    "    reference_line: str = Field(description=\"\")\n",
    "\n",
    "class YTSummaryResponse(BaseModel):\n",
    "    summary: str\n",
    "    chapters: list[Chapter]\n",
    "\n",
    "    def print(self):\n",
    "        print(self.summary)\n",
    "        print()\n",
    "\n",
    "        print('Chapters:')\n",
    "\n",
    "        for c in self.chapters:\n",
    "            print(f'{c.timestamp} {c.title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9a2252-f14a-4e2e-bc05-1e3b8ee03e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_structured(instructions, prompt, model='gpt-4o-mini', output=YTSummaryResponse):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': instructions},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.parse(\n",
    "        model=model,\n",
    "        input=messages,\n",
    "        text_format=output\n",
    "    )\n",
    "\n",
    "    return response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b163771-3bae-4120-bbdd-5a7e76799e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Engineering Buildcamp focuses on practical AI engineering, emphasizing building systems around AI rather than just the AI concepts themselves. The course has been designed to differentiate itself from the many existing AI boot camps. Participants will engage in building applications using an engineering mindset where testability and best practices are paramount. The course structure includes core and optional content, so students can navigate through essential topics while having the freedom to explore more advanced materials based on their interests or project needs.\n",
      "\n",
      "Throughout the course, students will learn how to interact with large language models (LLMs) like OpenAI as well as incorporate them into various applications. Each week will introduce new concepts and culminate in a capstone project that encourages creative problem-solving. The course also emphasizes collaboration through Slack for peer discussions and brainstorming ideas, laying a solid foundation for developing practical skills in AI engineering.\n",
      "\n",
      "Chapters:\n",
      "00:00 Course Introduction\n",
      "02:11 Platform Overview\n",
      "04:16 Course Navigation\n",
      "06:34 Core vs. Optional Content Explained\n",
      "08:51 Week 1 Focus: OpenAI and Rack\n",
      "12:30 Week 2: Environment Preparation and Extra Use Cases\n",
      "14:24 Course Homework and Project Ideas\n",
      "17:05 Course Framework & Agent Development\n",
      "19:30 Importance of Testing Agents\n",
      "21:24 Monitoring and Logging of Agents\n",
      "23:58 Final Week Overview and Capstone Projects\n",
      "26:01 Community Interaction and Slack Usage\n",
      "35:14 Using Tools and Libraries\n",
      "42:30 Project Management and GitHub\n",
      "51:38 Closing Remarks and Q&A\n"
     ]
    }
   ],
   "source": [
    "summary = llm_structured(\n",
    "    instructions=instructions,\n",
    "    prompt=subtitles,\n",
    "    model='gpt-4o-mini'\n",
    ")\n",
    "\n",
    "summary.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5559cecd-aae8-4f09-a7c8-c2e39a58d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are given a raw YouTube transcript as plain text. Each transcript line is formatted exactly like:\n",
    "\n",
    "[LINE_INDEX] TIMESTAMP text...\n",
    "\n",
    "Example:\n",
    "[0012] 08:03 So this is the library we're going to um\n",
    "\n",
    "Your job is to return ONLY valid JSON that matches the provided Pydantic schema (YTSummaryResponse).\n",
    "\n",
    "PRIMARY GOAL\n",
    "Create a YouTube description + a chapter list that provides FULL COVERAGE of the video:\n",
    "- Coverage must start at the FIRST timestamp in the transcript.\n",
    "- Coverage must end at the LAST timestamp in the transcript.\n",
    "- There must be NO uncovered gaps between chapters.\n",
    "  (The end of one chapter is the start of the next chapter.)\n",
    "- Therefore, the first chapter timestamp MUST equal the first transcript timestamp,\n",
    "  and the last chapter must extend to the end of the video (last transcript timestamp).\n",
    "\n",
    "OUTPUT FORMAT (STRICT)\n",
    "- Return ONLY a single JSON object.\n",
    "- Do not include any additional keys beyond the schema.\n",
    "- Do not include markdown, code fences, or extra commentary.\n",
    "\n",
    "SUMMARY RULES\n",
    "- Write 2–3 paragraphs of plain text (no bullet points, no headings, no markdown).\n",
    "- Do NOT start with: \"Welcome\", \"In this video\", \"Today we will\", \"The transcript...\", or similar framing.\n",
    "- The tone should fit a YouTube description: clear and informative.\n",
    "- Use the exact course name: \"AI Engineering Buildcamp\".\n",
    "- Do not add links unless they are explicitly present in the transcript.\n",
    "\n",
    "CHAPTER LIST RULES (FULL COVERAGE REQUIRED)\n",
    "- Chapters must be in chronological order.\n",
    "- Chapters must provide FULL COVERAGE from the first to the last timestamp as described above.\n",
    "- Each chapter should start exactly when a new concept/topic is introduced.\n",
    "- Aim for chapter length of 3–5 minutes.\n",
    "- Hard constraints: chapters must be at least 3 minutes long and at most 6 minutes long.\n",
    "- If strict topic boundaries would cause a chapter to be shorter than 3 minutes,\n",
    "  merge it with a neighboring topic.\n",
    "- If a topic runs longer than 6 minutes, split it into multiple chapters at sensible subtopic boundaries.\n",
    "- Create enough chapters to cover the entire duration; do not stop early.\n",
    "\n",
    "REFERENCE LINE RULES (CRITICAL — NO HALLUCINATIONS)\n",
    "- For each chapter you MUST choose exactly ONE anchor line from the transcript and copy it verbatim into `reference_line`.\n",
    "- `reference_line` MUST match one of the provided transcript lines character-for-character,\n",
    "  including the [LINE_INDEX] prefix, the timestamp, capitalization, filler words, and punctuation.\n",
    "- Do NOT paraphrase, rewrite, merge multiple lines, or \"clean up\" the text.\n",
    "- If you cannot find an exact transcript line to support a chapter start, do NOT include that chapter.\n",
    "  Instead, choose a different chapter boundary that DOES have an exact supporting line.\n",
    "\n",
    "TIMESTAMP RULES (CRITICAL)\n",
    "- `timestamp` MUST be taken from the anchor line you copied into `reference_line`.\n",
    "- `timestamp` MUST exactly equal the timestamp that appears inside `reference_line`.\n",
    "- Do NOT invent timestamps. Do NOT approximate. Do NOT shift by a few seconds.\n",
    "- The first chapter timestamp MUST equal the first transcript timestamp (full coverage).\n",
    "- Every next chapter timestamp must be later than the previous chapter timestamp.\n",
    "\n",
    "CHAPTER TITLE RULES\n",
    "- `title` should be 2–7 words.\n",
    "- Make it specific and descriptive (avoid vague titles like \"More details\" or \"Next steps\").\n",
    "- No quotes, emojis, or trailing punctuation.\n",
    "\n",
    "OPTIONAL CHAPTER SUMMARY\n",
    "- `chapter_summary` may be null or one concise sentence.\n",
    "- Keep it factual and specific; do not add new information not supported by the transcript.\n",
    "\n",
    "FINAL SELF-CHECK (DO THIS BEFORE YOU OUTPUT)\n",
    "1) Identify the first transcript timestamp and ensure the first chapter uses it.\n",
    "2) Identify the last transcript timestamp and ensure the last chapter reaches it.\n",
    "3) Ensure there are no gaps: each chapter starts where the previous one ends (i.e., next chapter timestamp is the boundary).\n",
    "4) Ensure each chapter duration is 3–6 minutes (target 3–5).\n",
    "5) Ensure every `reference_line` is an exact copy of a transcript line including [LINE_INDEX].\n",
    "6) Ensure every `timestamp` exactly matches the timestamp inside `reference_line`.\n",
    "\n",
    "If you cannot satisfy any rule, adjust chapter boundaries and/or increase the number of chapters.\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0772a4f9-59fa-4291-8890-2743b15d1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Chapter(BaseModel):\n",
    "    timestamp: str = Field(\n",
    "        description=\"Chapter start timestamp, must match the timestamp in reference_line, format is H:MM:SS or MM:SS.\"\n",
    "    )\n",
    "    title: str = Field(\n",
    "        description=\"5-15 word YouTube chapter title.\"\n",
    "    )\n",
    "    reference_line: str = Field(\n",
    "        description=(\n",
    "            \"A verbatim transcript line INCLUDING its numeric prefix and timestamp, \"\n",
    "            \"copied exactly from the provided subtitles. \"\n",
    "            \"Must match one of the provided lines character-for-character.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class YTSummaryResponse(BaseModel):\n",
    "    summary: str\n",
    "    chapters: list[Chapter]\n",
    "\n",
    "    def print(self):\n",
    "        print(self.summary)\n",
    "        print(\"\\nChapters:\\n\")\n",
    "        for c in self.chapters:\n",
    "            print(f\"{c.timestamp} {c.title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dfbe0e7-cff2-47e2-8ca6-3b395e0b80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_subtitles(subtitles: str) -> str:\n",
    "    lines = []\n",
    "    idx = 0\n",
    "\n",
    "    for raw in subtitles.split(\"\\n\"):\n",
    "        raw = raw.strip()\n",
    "        if not raw:\n",
    "            continue\n",
    "\n",
    "        lines.append(f\"[{idx:04d}] {raw}\")\n",
    "        idx += 1\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd051614-adea-4662-bfe1-a6051b12cbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'Chapter': {'properties': {'timestamp': {'description': 'Chapter start timestamp, must match the timestamp in reference_line, format is H:MM:SS or MM:SS.',\n",
       "     'title': 'Timestamp',\n",
       "     'type': 'string'},\n",
       "    'title': {'description': '5-15 word YouTube chapter title.',\n",
       "     'title': 'Title',\n",
       "     'type': 'string'},\n",
       "    'reference_line': {'description': 'A verbatim transcript line INCLUDING its numeric prefix and timestamp, copied exactly from the provided subtitles. Must match one of the provided lines character-for-character.',\n",
       "     'title': 'Reference Line',\n",
       "     'type': 'string'}},\n",
       "   'required': ['timestamp', 'title', 'reference_line'],\n",
       "   'title': 'Chapter',\n",
       "   'type': 'object'}},\n",
       " 'properties': {'summary': {'title': 'Summary', 'type': 'string'},\n",
       "  'chapters': {'items': {'$ref': '#/$defs/Chapter'},\n",
       "   'title': 'Chapters',\n",
       "   'type': 'array'}},\n",
       " 'required': ['summary', 'chapters'],\n",
       " 'title': 'YTSummaryResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTSummaryResponse.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe6a897-be24-4f5d-8ddb-0194b55eff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_subtitles = preprocess_subtitles(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "481f5551-c5ed-4434-9564-8591b2468aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first live session of AI Engineering Buildcamp explains the course rename and what “buildcamp” means: a hands-on AI engineering approach focused on building testable, production-minded systems around LLMs. The instructor walks through the Maven student portal, how the curriculum is organized by week, what content is core versus optional, and what the first weeks focus on—foundations, RAG, data preparation, search, and structured output.\n",
      "\n",
      "You’ll get a week-by-week overview of what’s coming next, including agents (with Pentic AI as the main framework and other frameworks as optional), testing and judge-based evaluation, monitoring/observability (OpenTelemetry, Pentic, Clockfire, Grafana), and evaluation with gold-standard datasets. The session also covers how communication works (Slack), how homework and submissions run via the course management platform, why “learning in public” is encouraged, how office hours operate (including time zone caveats), and how to set up your development environment (GitHub Codespaces and local). The video ends with Q&A on note-taking/second-brain workflows and a short discussion of student project ideas, plus a closing update about new materials rolling out over time.\n",
      "\n",
      "Chapters:\n",
      "\n",
      "00:00 Why Buildcamp and focus\n",
      "04:06 Core versus optional content\n",
      "08:03 Week 2 extras and examples\n",
      "11:01 Agents and frameworks in week 3\n",
      "14:04 Testing monitoring evaluation overview\n",
      "17:07 Project weeks deployment demos\n",
      "25:02 Slack communication and guidelines\n",
      "28:05 Homework submission platform\n",
      "30:10 Learning in public benefits\n",
      "33:00 Office hours and time zones\n",
      "36:58 Environment setup videos\n",
      "41:11 AI-assisted development tools\n",
      "45:23 Course libraries and week one recap\n",
      "48:23 Q&A second brain notes and projects\n",
      "56:41 Closing photo and next steps\n"
     ]
    }
   ],
   "source": [
    "summary = llm_structured(\n",
    "    instructions=instructions,\n",
    "    prompt=idx_subtitles,\n",
    "    output=YTSummaryResponse,\n",
    "    # model='gpt-4o-mini',\n",
    "    model='gpt-5.2',\n",
    ")\n",
    "\n",
    "summary.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "816d2a04-71f9-4b46-803c-57d989733899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chapter(timestamp='11:01', title='Agents and frameworks in week 3', reference_line='[0248] 11:01 Um but in addition to that as bonus')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.chapters[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95220323-b546-4c53-9bd2-06f9b2475902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[0238] 10:32 implement it we will start talking about',\n",
       " '[0239] 10:34 agents so week number three is devoted',\n",
       " '[0240] 10:37 to agents so we will what is the',\n",
       " '[0241] 10:40 difference between uh traditional rack',\n",
       " '[0242] 10:42 and agentic rock and what agents uh what',\n",
       " '[0243] 10:46 is an agent. So we are going to cover it',\n",
       " \"[0244] 10:49 here. Um we're I'm also going to\",\n",
       " '[0245] 10:52 introduce one main framework that we are',\n",
       " '[0246] 10:54 going to use as uh throughout the',\n",
       " '[0247] 10:57 course. The framework is called pentki.',\n",
       " '[0248] 11:01 Um but in addition to that as bonus',\n",
       " '[0249] 11:04 materials as optional materials I will',\n",
       " '[0250] 11:06 show you other frameworks. So last',\n",
       " '[0251] 11:09 cohort we had two frameworks as like',\n",
       " '[0252] 11:12 main frameworks open AAI agents SDK and',\n",
       " '[0253] 11:15 Pentic AI and um I found it confusing at',\n",
       " '[0254] 11:19 the end. So one of them became optional',\n",
       " '[0255] 11:21 but also in addition to open agent SDK',\n",
       " \"[0256] 11:24 I'm going to cover other frameworks like\",\n",
       " '[0257] 11:26 lchain crew AI and Google ADK right so']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_subtitles.split('\\n')[238:258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873ba9f-8d08-46ae-b00c-215aa2a1dbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
